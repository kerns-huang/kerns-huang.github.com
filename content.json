{"meta":{"title":"kerns的小窝","subtitle":"行走在路上，无愧于心。","description":"努力看书，努力扯淡。","author":"kerns","url":"http://yoursite.com"},"posts":[{"title":"centos7 bsc公链全节点搭建","slug":"bsc公链全节点搭建","date":"2021-09-18T06:44:27.000Z","updated":"2021-10-25T04:28:20.818Z","comments":true,"path":"2021/09/18/bsc公链全节点搭建/","link":"","permalink":"http://yoursite.com/2021/09/18/bsc公链全节点搭建/","excerpt":"","text":"快照安装过程前置条件安装git 环境安装12yum -y install https://packages.endpoint.com/rhel/7/os/x86_64/endpoint-repo-1.7-1.x86_64.rpmyum install git go 环境安装 下载地址 12标准官网：https://golang.org/ 需要墙镜像官网：https://golang.google.cn/dl/ 【国内推荐】 安装 1tar -zxf go*.linux-amd64.tar.gz -C /usr/local 添加环境变量 vi /etc/profile 1234export GO111MODULE=onexport GOROOT=/usr/local/goexport GOPATH=/home/gopathexport PATH=$PATH:$GOROOT/bin:$GOPATH/bin nginx 安装 12yum install epel-releaseyum install nginx 添加跨域配置 123456789location / &#123; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET, POST, OPTIONS, PUT, DELETE&apos;; add_header &apos;Access-Control-Allow-Headers&apos; &apos;Content-Type&apos;; proxy_pass http://localhost:8876; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; &#125; 安装 下载bsc 快照数据 使用快照的原因，从0开始同步数据会很慢，所以需要通过快照的加快区块的同步过程。 1https://github.com/binance-chain/bsc-snapshots 下载命令： 1nohup wget -O geth.tar.gz &quot;snapurl&quot; &gt;/dev/null 2&gt;log &amp; 下载 bsc 快照 1git clone https://github.com/binance-chain/bsc 编译geth 12cd bscmake geth 下载初始化配置文件 主网 12wget https://github.com/binance-chain/bsc/releases/download/v1.1.2/mainnet.zipunzip mainnet.zip 测试网络 12wget https://github.com/binance-chain/bsc/releases/download/v1.1.2/testnet.zipunzip testnet.zip config.toml 节点配置修改 12345678910[Node]IPCPath = &quot;geth.ipc&quot;HTTPHost = &quot;0.0.0.0&quot;NoUSB = trueInsecureUnlockAllowed = falseHTTPPort = 8876HTTPVirtualHosts = [&quot;*&quot;]HTTPModules = [&quot;eth&quot;, &quot;net&quot;, &quot;web3&quot;, &quot;txpool&quot;, &quot;parlia&quot;]WSPort = 8877 WSModules = [&quot;net&quot;, &quot;web3&quot;, &quot;eth&quot;] 初始化（当从快照执行的时候不用） 1geth --datadir node init genesis.json 运行 1nohup geth --config ./config.toml --datadir ./server/data-seed/geth --cache 32768 --rpc.allow-unprotected-txs --txlookuplimit 0 &gt;/dev/null 2&gt;&amp;1 &amp; cache: 以m为单位，缓存设置约大，同步数据越快,目前设置为32G。 一些常用的命令 查看节点最新同步的区块高度 1curl -s -H Content-Type:application/json -X POST --data &apos;&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;eth_blockNumber&quot;,&quot;params&quot;:[],&quot;id&quot;:1&#125;&apos; http://127.0.0.1:8876 查看是否同步完成 1curl -s -H Content-Type:application/json -X POST --data &apos;&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;eth_syncing&quot;,&quot;params&quot;:[],&quot;id&quot;:1&#125;&apos; http://127.0.0.1:8876 3. 123geth attach http://localhost:8876eth.syncingeth.blockNumber","raw":null,"content":null,"categories":[],"tags":[]},{"title":"使用python 调用 defi 函数","slug":"使用python-调用-defi-函数","date":"2021-09-16T21:30:11.000Z","updated":"2021-10-25T01:42:48.467Z","comments":true,"path":"2021/09/17/使用python-调用-defi-函数/","link":"","permalink":"http://yoursite.com/2021/09/17/使用python-调用-defi-函数/","excerpt":"","text":"安装 web3 py1pip install web3 连接节点的最常用方法是1231.IPC（使用本地文件系统：最快，最安全）2.Websockets（远程工作，比 HTTP 更快,但一般只有私人节点开发）3.HTTP（更多节点支持它） 具体的参考资料网上很多 合约调用代码demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&quot;&quot;&quot;swap 合约 新币抢链机器人&quot;&quot;&quot;import jsonimport requestsfrom web3 import Web3import timedef getAbi(contract_address): &quot;&quot;&quot; :param contract_address: 合约地址 &quot;&quot;&quot; url_scan = &quot;https://api.bscscan.com/api?module=contract&amp;action=getabi&amp;address=&quot; + str(contract_address) r = requests.get(url=url_scan) response = r.json() abi = json.loads(response[&quot;result&quot;]) return abi# 交换虚拟货币def swap(): contract_address = web3.toChecksumAddress(router_contract_address) contract = web3.eth.contract(address=contract_address, abi=contract_abi) # 交易对 pair = [token_in, token_out] amounts = contract.functions.getAmountsOut(amount_in, pair).call() amount_out_min = amounts[1] * (1 - slippage) if amount_out_min &lt; min_buy_token_amount: print(&quot;目前能买到的币数量为: &#123;0&#125;,最小购买的币数量为: &#123;1&#125;,已经小于最小购买数量&quot;.format(amount_out_min, min_buy_token_amount)) return # 开始交易 txn = contract.functions.swapExactTokensForTokens( amount_in, amount_out_min, pair, # 接收人的币种地址 address, (int(time.time()) + 10000) ).buildTransaction(&#123; &apos;chainId&apos;: 56, &apos;from&apos;: address, # 手续费根据需要加大 &apos;gas&apos;: gas, &apos;gasPrice&apos;: web3.eth.gasPrice, &apos;nonce&apos;: nonce, &#125;) signed_txn = web3.eth.account.sign_transaction(txn, private_key=private_key) tx_token = web3.eth.send_raw_transaction(signed_txn.rawTransaction) print(&quot;swap token tx is &#123;0&#125;&quot;.format(web3.toHex(tx_token)))if __name__ == &apos;__main__&apos;: # 币安的写成币安的地址 url = &quot;https://bsc-dataseed1.binance.org&quot; web3 = Web3(Web3.HTTPProvider(url)) # pancake 智能合约 router_contract_address = &quot;0x10ED43C718714eb63d5aA57B78B54704E256024E&quot; # 钱包私钥信息 private_key = &quot;&quot; # 钱包地址 address = web3.toChecksumAddress(&quot;&quot;) # 发送的币种信息 send_token_address = &quot;0xbb4CdB9CBd36B01bD1cBaEBF2De08d9173bc095c&quot; # 交易的币种信息 buy_token_address = &quot;0xfbb4f2f342c6daab63ab85b0226716c4d1e26f36&quot; # 交易的币数量 send_token_amount = 0.3 # 最小买入金额 min_buy_token_amount = 2000 # 燃烧的gas 费 gas = 7000000 # 间隔时间 split_second = 5 # 滑点 0.5 = 50% slippage = 0.5 amount_in = Web3.toWei(send_token_amount, &apos;ether&apos;) token_in = Web3.toChecksumAddress(send_token_address) token_out = Web3.toChecksumAddress(buy_token_address) nonce = web3.eth.getTransactionCount(address) while True: try: swap() nonce = nonce + 1 except ValueError as e: print(&quot;swap error &#123;0&#125;&quot;.format(e)) time.sleep(split_second)","raw":null,"content":null,"categories":[],"tags":[]},{"title":"gogs-drone自动化部署","slug":"drone自动化部署","date":"2020-12-23T06:42:00.000Z","updated":"2021-08-23T08:29:40.704Z","comments":true,"path":"2020/12/23/drone自动化部署/","link":"","permalink":"http://yoursite.com/2020/12/23/drone自动化部署/","excerpt":"","text":"第一步docker 部署docker 安装 docker-compose 安装 第二步 gogs drone compose 文件下载https://github.com/alicfeng/gogs-drone-docker.git cd gogs-drone-docker 1docker-compose up -d 启动完之后配置 gogs 地址 : http://ip:3000/ gogs类似gitlab，做代码管理的工具，刚开始安装的时候你需要自己创建帐号密码，然后把自己的项目推送到环境上去。 需要查看下钩子能否推送到drone这边，有可能配置错误，导致推送不成功。点击编辑里面有一个测试推送的设置，默认hook是不需要鉴权的。 drone 的默认地址: http://ip:8000/ 当gogs配置好之后，drone 默认基本不需要变动，不过服务器的配置可以在drone里面去配置，可以在.drone.yml里面写死，但是不如在drone配置可以统一管理和保密。 go 部署的文件配置下面的 host ，password 等就是在drone 工程里面配置的变量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061kind: pipelinename: code_manager_backstageworkspace: base: /var/goproject/src path: code_manager_backstagesteps: - name: build image: golang:1.14.4 environment: GOOS: linux GOARCH: amd64 commands: - export GOPATH=/var/goproject - export PATH=$PATH:$GOROOT/bin - go env -w GO111MODULE=on - go env -w GOPROXY=https://goproxy.io,direct - go version - go env - go mod tidy - go mod vendor - go build -i -o bin/code_manager_backstage main.go - name: deploy_server image: appleboy/drone-scp settings: host: from_secret: host port: from_secret: port username: from_secret: username password: from_secret: password target: from_secret: target source: ./bin rm: false when: branch: - master - name: run image: appleboy/drone-ssh settings: host: from_secret: host port: from_secret: port username: from_secret: username password: from_secret: password command_timeout: 2m script: - cd /generatecode/code_manager_backstage - rm -rf code_manager_backstage - cp bin/code_manager_backstage code_manager_backstage - ./restart.sh - nohup ./code_manager_backstage 1&gt;/code_manager_backstage/log/nohup`date +%Y-%m-%d`.log 2&gt;&amp;1 &amp;trigger: branch: - master","raw":null,"content":null,"categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"部署","slug":"部署","permalink":"http://yoursite.com/tags/部署/"}]},{"title":"团队协作工具整理","slug":"团队协作工具整理","date":"2020-12-15T02:57:32.000Z","updated":"2021-08-23T08:29:40.710Z","comments":true,"path":"2020/12/15/团队协作工具整理/","link":"","permalink":"http://yoursite.com/2020/12/15/团队协作工具整理/","excerpt":"","text":"办公聊天工具 slack 集成了很多的开发工具，你可以想安装插件一样在里面添加一些bug追踪工具，聊天的方式也更加的贴合远程协作的开发。对各个终端的支持也很全面，支持ios，android，mac和window端。 Rocket Chat slack 开源替代，没有聊天加密的功能 原型设计协作 axhub 墨刀 前后端交互 小幺鸡 java编写，开源，对于编写java的人而言，便于维护和继续扩展 yapi nodejs 编写，页面比小幺鸡美观舒服。做文档是不错 swagger java的文档标准，在go上也支持，可以在代码里面直接通过文档的方式生成。 公司文档整理 gitbook : 代码规范制定，可以生成epub等电子书，功能比较强大。安装： 12yum install npmnpm install gitbook-cli -g 常用的命令： 12服务启动：gitbook serve编译 : gitbook build 参考的地址 ：https://gitee.com/kernsjava/code_rule.git docsify ： 如果嫌弃gitbook build 太慢，没有那么多需要转换的功能，可以用这个。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"centos firewall管理","slug":"centos-firewalld","date":"2020-11-06T02:35:00.000Z","updated":"2021-08-23T08:29:40.704Z","comments":true,"path":"2020/11/06/centos-firewalld/","link":"","permalink":"http://yoursite.com/2020/11/06/centos-firewalld/","excerpt":"","text":"查看所有打开的端口 1firewall-cmd --zone=public --list-ports 永久添加端口 1firewall-cmd --zone=public --add-port=80/tcp --permanent 更新防火墙规则 1firewall-cmd --reload 删除端口 1firewall-cmd --zone= public --remove-port=80/tcp --permanent","raw":null,"content":null,"categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"},{"name":"linux","slug":"运维/linux","permalink":"http://yoursite.com/categories/运维/linux/"}],"tags":[]},{"title":"mysql 问题定位","slug":"mysql连接数问题","date":"2020-10-23T00:56:00.000Z","updated":"2021-08-23T08:29:40.707Z","comments":true,"path":"2020/10/23/mysql连接数问题/","link":"","permalink":"http://yoursite.com/2020/10/23/mysql连接数问题/","excerpt":"","text":"查看连接数问题查看执行中的进程SHOW FULL PROCESSLIST;show processlist; 查看最大连接数show variables like ‘%max_connections%’; 8.0 中设置最大连接数set persist max_connections=200;","raw":null,"content":null,"categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"selenium 爬虫","slug":"selenium-爬虫","date":"2020-09-14T13:13:00.000Z","updated":"2021-09-06T07:30:04.324Z","comments":true,"path":"2020/09/14/selenium-爬虫/","link":"","permalink":"http://yoursite.com/2020/09/14/selenium-爬虫/","excerpt":"","text":"安装 seleniumpip install -U selenium ps: 在安装的过程中如果遇到被墙的问题的，很容易 timeout 在mac 环境下需要修改下载源 1234cd ~mkdir .pipcd .pipvim pip.conf 接着进入vim编辑，写入 1234[global]index-url=http://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com 内核安装crome selenium 等待页面加载完成。强制等待,目前用着是最好用的一个操作， 1time.sleep 隐式等待 1driver.implicitly_wait(10) 显示等待，有些时候执行不成功，具体原因还得定位，在python里面不好用，在java里面挺好用的 123element = WebDriverWait(driver, 10).until( EC.presence_of_element_located((By.XPATH, &apos;//*[@id=&quot;su&quot;]&apos;)) ) 后台执行当需要在服务端运行的时候，这个非常有用。 12345chrome_options = Options()chrome_options.add_argument(&apos;--headless&apos;) chrome_options.add_argument(&apos;--no-sandbox&apos;)chrome_options.add_argument(&apos;--disable-dev-shm-usage&apos;)chrome_options.add_argument(&apos;--disable-gpu&apos;)dr = webdriver.Chrome(chrome_options=chrome_options) form 表单模拟登陆如下，非常简单的操作，通过send_keys 就可以给表单对象设置value 12345uInput = dr.find_element_by_id(&quot;username&quot;)uInput.send_keys(&quot;name&quot;)passInput = dr.find_element_by_id(&quot;password&quot;)passInput.send_keys(&quot;pasword&quot;)dr.find_element_by_class_name(&quot;btn-login&quot;).click() 调用对应的事件java: 12Actions action = new Actions(driver);action.doubleClick(tds.get(2)).perform(); 回退和前进java 回退 1driver.navigate().back(); java 前进 1driver.navigate().forward(); 多页面，切换页面12345Set&lt;String&gt; set = driver.getWindowHandles();for (String handle : set) &#123; driver.switchTo().window(handle); //获取满足条件的 页面&#125; selenium 反爬机制目前在爬取 问财 网站的时候遇到了 反爬的机制，反爬机制的原因是因为selenium的一个特征机制被识别，导致爬虫失效。可以添加 如果配置项消除 selenium 特征。 12chrome_options.add_argument(&quot;--disable-blink-features&quot;)chrome_options.add_argument(&quot;--disable-blink-features=AutomationControlled&quot;) selenium方式的优劣 优势：虽然通过浏览器内核，是简单的通过http模拟是媲美不了的，如果ajax很多，而且有很多拼接操作的页面，通过http请求，分析各个接口的含义需要花很多的时间，这个时候通过selenium通过浏览器内核直接抓取页面元素会方便很多。 劣势：比如模拟表单提交，如果ajax请求很少，或者没有，只有一次请求，但是又有很多动态的元素生成，这种情况下直接分析请求报文是更简单的操作。 参考资料http://www.python66.com/seleniumjiaocheng/182.html","raw":null,"content":null,"categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"fabric 链包开发和部署","slug":"fabric链包部署","date":"2020-09-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.705Z","comments":true,"path":"2020/09/02/fabric链包部署/","link":"","permalink":"http://yoursite.com/2020/09/02/fabric链包部署/","excerpt":"","text":"下载 fabric-sample 工程master不稳定，可能部署不成功，切换到release-1.4 测试链码1进入目录 chaincode-docker-devmode执行 1docker-compose -f docker-compose-simple.yaml up 如果执行不成功，建议指定docker 版本号，目前我跑的是1.4.8 如果没有错误的话，我们的开发环境已经准备好了，接下来是对链码进行测试的步骤： 将编写的链码放到fabric-sample/chaincode/文件夹下 2打开第二个终端执行：1docker exec -it chaincode sh 编译链码,以官方的例子为例： 123cd chaincode_example02/gogo build -o chaincode_example02CORE_PEER_ADDRESS=peer:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./chaincode_example02 3.安装与实例化和测试：打开第三个终端执行： 1docker exec -it cli bash 以下命令按照自己的链码内容自行修改12peer chaincode install -p chaincodedev/chaincode/chaincode_example02/go -n mycc -v 0peer chaincode instantiate -n mycc -v 0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]&#125;&apos; -C myc 测试调用 set() 接口将 a 的值设置为20:1peer chaincode invoke -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;set&quot;, &quot;a&quot;, &quot;20&quot;]&#125;&apos; -C myc 调用 get() 接口查询 a 的值，发现a的值已经更新为20，测试完毕。1peer chaincode query -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;get&quot;,&quot;a&quot;]&#125;&apos; -C myc","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"http://yoursite.com/categories/go/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/区块链/"}]},{"title":"限流问题","slug":"限流问题","date":"2020-08-26T12:24:00.000Z","updated":"2021-08-23T08:29:40.712Z","comments":true,"path":"2020/08/26/限流问题/","link":"","permalink":"http://yoursite.com/2020/08/26/限流问题/","excerpt":"","text":"基本的概念：限流是为了解决流量超出服务器的承载量，为了保证服务器的稳定性而做的折中方案。通用的实现方式计数器代码实现具体实现 缺点临界问题，11:59:59 秒100个请求，12:00:01秒 又100个请求，导致请求超出服务器的承载能力。 滑动窗口限流基本原理比如限流是按照1分钟100次，我细分为60个时间间隔，第一秒消耗了多少个，我新增一秒 代码实现具体实现 优点避免了固定窗口的突发请求 缺点设置精度越高，算法消耗的空间越大精度低和固定窗口效果类似。 漏斗算法令牌桶算法代码实现1 常用的资源隔离线程池信号量","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"http://yoursite.com/tags/高并发/"}]},{"title":"锁-未完成","slug":"锁","date":"2020-08-21T08:18:00.000Z","updated":"2021-08-23T08:29:40.712Z","comments":true,"path":"2020/08/21/锁/","link":"","permalink":"http://yoursite.com/2020/08/21/锁/","excerpt":"","text":"操作系统级别如何实现锁系统级别锁的实现互斥锁基本概念互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。 自旋锁基本概念自旋锁是专为防止多处理器并发而引入的一种锁，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁。在多核环境下，操作系统通过锁内存总线这个机制保证锁的唯一性。 使用场景只有在占用锁的时间极短的情况下，使用自旋锁才是合理的 注意事项是递归使用一个自旋锁，即如果一个已经拥有某个自旋锁的CPU 想第二次获得这个自旋锁，则该CPU 将死锁。 java 级别如果实现锁基本概念调用操作系统 具体的实现可重入锁可重入锁的概念，持有锁的线程可以重复持有该锁。 自己实现的可重入锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class LocalReentrantLock &#123; private AtomicReference&lt;Thread&gt; owner; /** * 被获取的次数 */ private AtomicInteger counter; private LinkedBlockingQueue&lt;Thread&gt; waitQueue; public LocalReentrantLock() &#123; //阻塞队列 waitQueue = new LinkedBlockingQueue(100); counter = new AtomicInteger(0); owner=new AtomicReference&lt;&gt;(); &#125; /** * 一直尝试获取锁 */ public void lock() &#123; if (!tryLock()) &#123; //如果获取不到锁，放入到等待队列 waitQueue.offer(Thread.currentThread()); while (true) &#123; //取头部数据 Thread head = waitQueue.peek(); if (head == Thread.currentThread()) &#123; //如果头部等于当前线程 if (!tryLock()) &#123; //如果获取不到锁，说明是其它线程还占有的锁。挂起之后什么时候唤醒了，unlock的时候唤醒？ LockSupport.park(); &#125; else &#123; //获取到了锁，直接弹出当前线程。 waitQueue.poll(); return; &#125; &#125; else &#123; LockSupport.park(); &#125; &#125; &#125; &#125; /** * 尝试获取锁，获取不到锁，直接返回false * * @return */ public boolean tryLock() &#123; int count = counter.get(); if (count &gt; 0) &#123; if (owner.get() == Thread.currentThread()) &#123; //拥有人是当前当前线程 counter.compareAndSet(count, count + 1); return true; &#125; else &#123; //把当前线程放到等待队列里面 return false; &#125; &#125; else &#123; if (counter.compareAndSet(count, count + 1)) &#123; //如果当前线程能够设置成1，设置所有人为当前现线程。 owner.set(Thread.currentThread()); return true; &#125; else &#123; //被其它的线程抢占，设置了，直接返回false return false; &#125; &#125; &#125; /** * 尝试解锁 */ public boolean tryUnlock() &#123; int count = counter.get(); if (count &gt; 0) &#123; if (owner.get() != Thread.currentThread()) &#123; throw new IllegalMonitorStateException(&quot;不能释放不是自己的锁&quot;); &#125; // 这里面不做多线程的考虑，因为上面已经保证了操作下面方法的肯定是拥有人线程。 count = count - 1; //设置引用次数减一 counter.set(count); if (count == 0) &#123; owner.set(null); return true; &#125; return false; &#125; else &#123; throw new IllegalMonitorStateException(&quot;锁已经释放&quot;); &#125; &#125; /** * 解除锁定 */ public void unlock() &#123; if(tryUnlock())&#123; //先释放当前锁的拥有人，如果可以释放，唤醒头部线程。 Thread head= waitQueue.peek(); if(head!=null)&#123; /** * 解锁头部线程 */ LockSupport.unpark(head); &#125; &#125; &#125;&#125; 测试用例1234567891011121314151617181920public static void main(String[] args) throws Exception &#123; LocalReentrantLock localReentrantLock = new LocalReentrantLock(); localReentrantLock.lock(); Thread.sleep(1000l); System.out.println(&quot;主线程第一次获取锁&quot;); new Thread(() -&gt; &#123; localReentrantLock.lock(); System.out.println(&quot;t1 线程第一次获取锁&quot;); localReentrantLock.unlock(); System.out.println(&quot;t1 线程解锁他获取的锁&quot;); &#125;).start(); localReentrantLock.lock(); Thread.sleep(1000l); System.out.println(&quot;主线程第二次获取锁&quot;); localReentrantLock.unlock(); System.out.println(&quot;主线程第一次释放锁&quot;); localReentrantLock.unlock(); System.out.println(&quot;主线程第二次释放锁&quot;); Thread.sleep(1000l); &#125; 读写锁分布式锁实现方式基于redis的实现方式reddsion 基于zookeeper的实现方式curator","raw":null,"content":null,"categories":[],"tags":[]},{"title":"java高并发细节优化","slug":"jvm优化","date":"2020-08-07T13:50:00.000Z","updated":"2021-08-23T08:29:40.707Z","comments":true,"path":"2020/08/07/jvm优化/","link":"","permalink":"http://yoursite.com/2020/08/07/jvm优化/","excerpt":"","text":"逃逸分析和栈上分配 逃逸分析： 就是分析出对象的作用域。当一个对象在方法体内声明后，该对象的引用被其他外部所引用时该对象就发生了逃逸，反之就会在栈帧中为对象分配内存空间。就是一个对象如果尽量在自己的方法区内调用，能增加方法执行的效率。 user1: 12345@Datapublic class User &#123; private String id; private String name;&#125; user1的测试时间： user2: 12345678910111213141516171819202122232425public class User &#123; private String id; private String name; private ArrayList&lt;String&gt; tt=new ArrayList&lt;&gt;(); public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; user2 测试的执行时间 测试代码123456789101112131415public class UserTest &#123; public static void alloc() &#123; User user = new User(); user.setId(&quot;12123&quot;); user.setName(&quot;1231231&quot;); &#125; public static void main(String[] args) &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024 * 1024; i++) &#123; alloc(); &#125; System.out.println(System.currentTimeMillis() - start); &#125;&#125; 两者之间的区别只是加了一个 ArrayList，效率的区别是几千倍。出现这种情况是因为 栈空间是有限的，而列表可以添加的数据是不确定的，所以jvm默认是不会把该对象放在栈空间，而只是放在堆空间。 jvm关闭逃逸分析 1-XX:-DoEscapeAnalysis jdk1.6之后默认情况下是开启的，正常情况也没有理由去关闭，毕竟能够更好的提神效率。 使用Integer的优化如果项目里面对于Integer的重复使用频率很高，Integer的优化主要是基于java代码的优化下面的方法会优先使用缓存返回。而缓存的返回，可以继续看源码 high的值你可以通过 环境变量去设置。 当然基于这种原理，如果你实现知道自己会使用很多重复的Long类型，也可以使用这种方式去优化,Long 里面其实也有cache 但是写死了只有-128 到127 ，如果需要更多，可以直接写一个类，做数据的缓存。","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"http://yoursite.com/tags/高并发/"}]},{"title":"黑科技收集-持续更新","slug":"黑科技收集-持续更新","date":"2020-08-05T02:48:54.000Z","updated":"2021-08-23T08:29:40.712Z","comments":true,"path":"2020/08/05/黑科技收集-持续更新/","link":"","permalink":"http://yoursite.com/2020/08/05/黑科技收集-持续更新/","excerpt":"","text":"密码破解工具HashCat sql 注入sqlmap 端口扫描nmap 操作系统kali linux wifi攻击与钓鱼 fluxion windows密码提取 mimikatz","raw":null,"content":null,"categories":[],"tags":[]},{"title":"高并发之请求合并","slug":"高并发之请求合并","date":"2020-07-27T13:52:00.000Z","updated":"2021-08-23T08:29:40.712Z","comments":true,"path":"2020/07/27/高并发之请求合并/","link":"","permalink":"http://yoursite.com/2020/07/27/高并发之请求合并/","excerpt":"","text":"如果我们没有在高并发场景下，我们获取单个用户信息 1234567891011121314public class UserServiceImpl implements UserService &#123; @Override public User getById(Integer id) &#123; try &#123; //这段代码代码该方法的正常耗时 Thread.sleep(10l); User user = new User(); user.setId(id); return user; &#125;catch (Exception e)&#123; return null; &#125; &#125;&#125; 但在面向大批量to c的用户场景下，用户的请求会出现毛刺的现象。比如某段时间逛的人特别多，获取用户信息，或者商品信息的请求某段时间突然变大，导致单台服务器支持不住，如果做流控的话，体验不是很好。 在这种情况下，两种办法： 1: 添加服务器 2: 请求合并 添加服务器简单有效，但是成本上去了，请求合并能够解决单台服务器的吞吐量的问题，那么上面的代码需要变成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class MergeUserServiceImpl implements UserService &#123; static class Request &#123; Integer id; CompletableFuture future; public Request(Integer id, CompletableFuture future) &#123; this.id = id; this.future = future; &#125; &#125; private LinkedBlockingQueue&lt;Request&gt; linkedBlockingQueue = new LinkedBlockingQueue&lt;Request&gt;(1000); public MergeUserServiceImpl()&#123; init(); &#125; private void init() &#123; ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(1); scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; //1.从阻塞队列中取出queue的请求，生成一次批量查询。 int size = linkedBlockingQueue.size(); if (size == 0) &#123; return; &#125; List&lt;Request&gt; requests = new ArrayList&lt;&gt;(size); for (int i = 0; i &lt; size; i++) &#123; // 移出队列，并返回。 Request poll = linkedBlockingQueue.poll(); requests.add(poll); &#125; //2.组装一个批量查询请求参数。 List&lt;Integer&gt; ids = new ArrayList&lt;&gt;(); for (Request request : requests) &#123; ids.add(request.id); &#125; //3. http 请求，或者 dubbo 请求。批量请求，得到结果list。 System.out.println(&quot;本次合并请求数量：&quot;+ids.size()); //请求 Map&lt;Integer, User&gt; responses = new HashMap&lt;&gt;(); for(Integer id:ids)&#123; User user=new User(); user.setId(id); responses.put(id,user); &#125; Thread.sleep(100l); //4.将结果响应给每一个单独的用户请求。 for (Request request : requests) &#123; //根据请求中携带的能表示唯一参数，去批量查询的结果中找响应。 User user= responses.get(request.id); //将结果返回到对应的请求线程。2个线程通信，异步编程赋值。 //complete(),源码注释翻译：如果尚未完成，则将由方法和相关方法返回的值设置为给定值 request.future.complete(user); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; // 立即执行任务，并间隔10 毫秒重复执行。 &#125;, 0, 10, TimeUnit.MILLISECONDS); &#125; public User getById(Integer id) &#123; CompletableFuture&lt;User&gt; future = new CompletableFuture(); linkedBlockingQueue.offer(new Request(id, future)); try &#123; return future.get(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; return null; &#125;&#125; 这么做的好处，可以合并io的操作，可以使用redis的pipline spring cloud 下Hystrix请求合并demo1demo2 在spring 环境下的请求合并，使用了Spring的注解，逻辑思路还是如上面所示。","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"http://yoursite.com/tags/高并发/"}]},{"title":"h2 数据库源码阅读","slug":"h2-数据库源码阅读","date":"2020-07-24T02:28:00.000Z","updated":"2021-08-23T08:29:40.706Z","comments":true,"path":"2020/07/24/h2-数据库源码阅读/","link":"","permalink":"http://yoursite.com/2020/07/24/h2-数据库源码阅读/","excerpt":"","text":"1:添加一行数据获取初始保存点遍历索引，添加数据的到索引里面。if 异常： 回滚到保存点。 MvPrimaryIndex中如果有事务： 添加数据到undo日志文件中 核心代码 MvTable 1","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Spring boot 类加载机制","slug":"Spring-boot-类加载机制","date":"2020-07-21T14:41:29.000Z","updated":"2021-08-23T08:29:40.703Z","comments":true,"path":"2020/07/21/Spring-boot-类加载机制/","link":"","permalink":"http://yoursite.com/2020/07/21/Spring-boot-类加载机制/","excerpt":"","text":"spring boot的类加载机制其实和Spring 没有什么不同，如果有什么不同的，以前需要写一堆的xml配置文件来来申明类和类之间的关系，现在基本上不需要写这么多配置文件了。这说明Spring boot在Spring上还是做了优化了，能让程序员更好更快的开发自己的程序。那么主要是那个变化省去了我们可以不用去写xml的麻烦。 扫描 -&gt; 注册 - 生成bean 扫描注册类的过程如下： 获取bean的过程 核心类 BeanDefinition: Bean的定义类, 和xml里的配置一一对应; BeanFacotry: Bean工厂接口; BeanDefinitionRegistry: BeanDefinition的注册定义接口; DefaultListableBeanFactory: ListableBeanFactory（extends BeanFactory）和BeanDefinitionRegistry的默认实现，提供BeanDefinition注册功能; ApplicationContext: Spring上下文环境; AbstractApplicationContext: 执行refresh()方法; AbstractRefreshableApplicationContext： 提供抽象方法loadBeanDefinitions(DefaultListableBeanFactory beanFactory) 用于加载BeanDefinition. plantUML 参考资料https://juejin.im/post/5c072b62e51d4520cf0ed5f8","raw":null,"content":null,"categories":[],"tags":[]},{"title":"spring boot 优雅关闭","slug":"spring-boot-优雅关闭","date":"2020-07-21T02:20:00.000Z","updated":"2021-08-23T08:29:40.708Z","comments":true,"path":"2020/07/21/spring-boot-优雅关闭/","link":"","permalink":"http://yoursite.com/2020/07/21/spring-boot-优雅关闭/","excerpt":"","text":"为什么要研究这个？开始开发系统的时候，系统部署上线，很容易执行kill -9 执行系统的关闭，但该关闭会有问题，一个是如果老板正在执行操作，你在重新部署系统，结果就是在老板那边各种拒绝服务错误，还有一个可能在系统重启之后，老板的数据存入操作一直失败，一查原因，竟然是有个操作只执行了一半，后面的没有执行。然后就被老板一顿喷。所以一般情况下，我们需要使用kill -15 来执行关闭操作，虽然拒绝服务不能解决，这个在微服务中可以使用移除注册中心注册来解决。但是能解决数据被操作一半，系统就关闭的问题。当然更难受的是用户数据错乱，导致用户体验差，而导致老板认为你们做了一个玩具！！！ spring boot里面如何实现目前 Spring boot 2.3 已经实现了优雅关闭的逻辑 在yml 里面配置 1234567# 开启优雅关闭server: shutdown: graceful# 关闭的缓冲时间，如果超过了10秒，Springboot 还是会选择强制关闭 spring: lifecycle: timeout-per-shutdown-phase: 10s 如下图：默认在spring boot 里面关闭是直接关闭的，意思是即使你使用kill -15 ，spring boot 也会立即关闭。 自己实现一个优雅停机的概念其实就是当我要关闭主线程的时候，当还有请求在处理，我先需要处理完请求，然后再去执行关闭的任务。举个例子，通常我们的服务是跑在tomcat上面的，那么我们需要知道tomcat的请求链接应该是在任务处理完成之后关闭的。 普通的java程序如果实现优雅停机添加 Runtime.getRuntime().addShutdownHook(this); 钩子程序 12345678910111213141516171819202122232425262728293031323334353637383940/** * 关闭之后的钩子 * * @author xiaohei * @create 2020-07-21 上午9:25 **/public class ShutdownHook extends Thread &#123; private boolean needShutDown = false; private Thread mainThread; public void run() &#123; System.out.println(&quot;钩子线程已经接到退出信号&quot;); needShutDown = true; //打断主线程的关闭 mainThread.interrupt(); try &#123; //等待主线程死亡 mainThread.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //TODO 正常情况下，这需要执行主线程死亡的回收任务，比如拒绝服务，线程池的关闭等操作 System.out.println(&quot;钩子线程会在主线程死亡之后死去，结束钩子生活&quot;); &#125; public ShutdownHook(Thread mainThread) &#123; this.mainThread = mainThread; this.needShutDown = false; //在这添加关闭的钩子线程 Runtime.getRuntime().addShutdownHook(this); &#125; public boolean isShutDown() &#123; return needShutDown; &#125;&#125; 主程序 12345678910111213141516171819202122232425262728293031323334353637/** * 测试主线程 * * @author xiaohei * @create 2020-07-21 上午9:32 **/public class TestMain &#123; private ShutdownHook shutdownHook; public static void main(String[] args)&#123; TestMain testMain=new TestMain(); System.out.println(&quot;开始执行测试&quot;); testMain.exec(); System.out.println(&quot;结束测试&quot;); &#125; public TestMain()&#123; //当前线程是主线程。 shutdownHook=new ShutdownHook(Thread.currentThread()); &#125; public void exec()&#123; while (!shutdownHook.isShutDown())&#123; System.out.println(&quot;睡眠1秒钟&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;主线程睡眠被打断&quot;); &#125; System.out.println(&quot;我已经活过来了&quot;); &#125; System.out.println(&quot;关闭钩子已经执行完成&quot;); &#125;&#125; spring boot内置容器下如何实现 优雅关闭？//TODO 需要思考 spring boot 外置容器下如何实现优雅关闭。//TODO 需要思考 参考资料https://www.jianshu.com/p/0c49eb23c627","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://yoursite.com/tags/spring-boot/"},{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"go gin web 初探","slug":"go-web-初探","date":"2020-07-20T01:57:00.000Z","updated":"2021-08-23T08:29:40.705Z","comments":true,"path":"2020/07/20/go-web-初探/","link":"","permalink":"http://yoursite.com/2020/07/20/go-web-初探/","excerpt":"","text":"1 ：gin 开发web使用goland新建一个go mod工程， 简单的 hello word 程序 12345678910111213import ( &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)func main()&#123; engine := gin.Default() engine.GET(&quot;test&quot;,func(c *gin.Context)&#123; c.JSON(http.StatusOK,gin.H&#123;&quot;code&quot;:200,&quot;msg&quot;:&quot;hell word&quot;&#125;) &#125;) engine.Run(&quot;:8089&quot;)&#125; 2: 一般的web开发，总会使用到数据库，最常用的数据库就是mysql，所以我们需要引入mysql。我们需要引入 mysql 的支持 1go get github.com/go-sql-driver/mysql 然后代码变成了 123456789func main()&#123; engine := gin.Default() engine.POST(&quot;test&quot;,func(c *gin.Context)&#123; db, err := sql.Open(&quot;mysql&quot;, &quot;user:password@tcp(ip:port)/dbname&quot;) db.Exec(&quot;insert into user values(?,?)&quot;,1,&quot;张三&quot;) c.JSON(http.StatusOK,gin.H&#123;&quot;code&quot;:200,&quot;msg&quot;:&quot;hell word&quot;&#125;) &#125;) engine.Run(&quot;:8089&quot;)&#125; 3 如2那样的代码，sql直接写在代码里面会不会不是太符合面向对象的逻辑，是否能够逻辑结构更清晰一点。在这个阶段 gorm 登场 1go get github.com/jinzhu/gorm 这个阶段把数据库的链接单独拿出来，整理一个单独的go文件 123456789101112131415package dbimport _ &quot;github.com/go-sql-driver/mysql&quot;import &quot;github.com/jinzhu/gorm&quot;var SqlDB *gorm.DBfunc init() &#123; //创建一个数据库的连接 var err error SqlDB, err = gorm.Open(&quot;mysql&quot;, &quot;username:password@tcp(ip:port)/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local&quot;) if err != nil &#123; panic(&quot;failed to connect database&quot;) &#125;&#125; 定义一个单独的 user model 类 1234567891011121314import ( &quot;chain-web/user-web/db&quot;)type User struct &#123; ID int64 `json:&quot;id&quot;` Name string `form:&quot;name&quot; json:&quot;name&quot; binding:&quot;required&quot;`&#125;//操作用户指针，不需要返回IDfunc (user *User) Insert() (err error) &#123; //添加数据 err = db.SqlDB.Create(&amp;user).Error return err&#125; main 方法变为 12345678910func main()&#123; engine := gin.Default() engine.POST(&quot;test&quot;,func(c *gin.Context)&#123; var user model.User c.ShouldBind(user) user.Insert() c.JSON(http.StatusOK,gin.H&#123;&quot;code&quot;:200,&quot;msg&quot;:&quot;hell word&quot;&#125;) &#125;) engine.Run(&quot;:8089&quot;)&#125; 在这个场景下，我们还可以把 路径和具体实现这块单独抽离出来，定一个router的包,response的返回一般情况下我们会有同一个的格式，所以也会抽离出来，具体的实现也会抽离，所以结构会变成如下 123456web db //数据库的配置 handler //具体的controller实现 router // 路由的配置 response //response统一格式返回 model // 数据库的操作，user.Insert()之类。 db.mysql.go 12345678910111213import _ &quot;github.com/go-sql-driver/mysql&quot;import &quot;github.com/jinzhu/gorm&quot;var SqlDB *gorm.DBfunc init() &#123; //创建一个数据库的连接 var err error SqlDB, err = gorm.Open(&quot;mysql&quot;, &quot;username:password@tcp(ip:port)/dbname?charset=utf8&amp;parseTime=True&amp;loc=Local&quot;) if err != nil &#123; panic(&quot;failed to connect database&quot;) &#125;&#125; model.user.go 1234567891011121314import ( &quot;chain-web/user-web/db&quot;)type User struct &#123; ID int64 `json:&quot;id&quot;` Name string `form:&quot;name&quot; json:&quot;name&quot;` &#125;//操作用户指针，不需要返回IDfunc (user *User) Insert() (err error) &#123; //添加数据 err = db.SqlDB.Create(&amp;user).Error return err&#125; handler.handler.go 12345678910111213141516import ( &quot;chain-web/user-web/model&quot; &quot;chain-web/user-web/response&quot; &quot;github.com/gin-gonic/gin&quot;)func Insert(c *gin.Context) &#123; var user model.Test c.ShouldBind(&amp;user) err :=user.Insert() if err != nil&#123; response.FailWithMessage(&quot;数据保存失败&quot;,c) &#125;else &#123; response.Ok(c) &#125;&#125; response.go 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package responseimport ( &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)type Response struct &#123; Code int `json:&quot;respCode&quot;` Msg string `json:&quot;respMsg&quot;` Data interface&#123;&#125; `json:&quot;respData&quot;`&#125;const ( ERROR = 7 SUCCESS = 0)func Result(code int, data interface&#123;&#125;, msg string, c *gin.Context) &#123; // 开始时间 c.JSON(http.StatusOK, Response&#123; code, msg, data, &#125;)&#125;func Ok(c *gin.Context) &#123; Result(SUCCESS, map[string]interface&#123;&#125;&#123;&#125;, &quot;操作成功&quot;, c)&#125;func OkWithMessage(message string, c *gin.Context) &#123; Result(SUCCESS, map[string]interface&#123;&#125;&#123;&#125;, message, c)&#125;func OkWithData(data interface&#123;&#125;, c *gin.Context) &#123; Result(SUCCESS, data, &quot;操作成功&quot;, c)&#125;func OkDetailed(data interface&#123;&#125;, message string, c *gin.Context) &#123; Result(SUCCESS, data, message, c)&#125;func Fail(c *gin.Context) &#123; Result(ERROR, map[string]interface&#123;&#125;&#123;&#125;, &quot;操作失败&quot;, c)&#125;func FailWithMessage(message string, c *gin.Context) &#123; Result(ERROR, map[string]interface&#123;&#125;&#123;&#125;, message, c)&#125;func FailWithDetailed(code int, data interface&#123;&#125;, message string, c *gin.Context) &#123; Result(code, data, message, c)&#125; router.go 1234567891011import &quot;github.com/gin-gonic/gin&quot;import .&quot;chain-web/user-web/handler&quot;func Init(router *gin.Engine) &#123; outAuthRouter(router)&#125;// 不需要认证的接口func outAuthRouter(router *gin.Engine) &#123; v1 := router.Group(&quot;/api/v1&quot;) v1.POST(&quot;/test/insert&quot;, Insert)&#125; 4 参数的校验在java环境中，特别是Spring环境中，我们可以使用valid 注解来做参数的自动化校验，去掉了很多和主要业务无关的代码，在go里面，是用什么样的方式去处理的？ 5 一般的web开发还涉及 登陆，注册，权限状态的变化。6 接口文档swagger的引入。7 配置文件的引入如上面看到的，mysql，端口号的配置，我们是硬编码在程序里面，在go 里面我们有没有什么好的方式去更灵活的配置呢？可以使用viper，viper 类似与淘宝的diamond，现在的nacos，可以灵活的去配置我们的配置。 1go get github.com/spf13/viper 添加 config.yaml文件 1234567891011settings: database: name: dbname dbType: mysql host: ip username: username password: password port: port max-idle-conns: 10 max-open-conns: 10 log-mode: false 添加 config.go 12345678910111213141516171819202122232425262728293031323334353637383940414243package configimport ( &quot;fmt&quot; &quot;github.com/spf13/viper&quot; &quot;log&quot;)var cfgDatabase *viper.Viperfunc Init() &#123; viper.AddConfigPath(&quot;./user-web/config&quot;) err := viper.ReadInConfig() if err != nil &#123; log.Fatal(fmt.Sprintf(&quot;Parse config file fail: %s&quot;, err.Error())) &#125; cfgDatabase = viper.Sub(&quot;settings.database&quot;) if cfgDatabase == nil &#123; panic(&quot;config not found settings.database&quot;) &#125; DatabaseConfig = InitDatabase(cfgDatabase)&#125;type Database struct &#123; Name string DBType string Host string Port int Username string Password string&#125;func InitDatabase(cfg *viper.Viper) *Database &#123; return &amp;Database&#123; Port: cfg.GetInt(&quot;port&quot;), Name: cfg.GetString(&quot;name&quot;), Host: cfg.GetString(&quot;host&quot;), Username: cfg.GetString(&quot;username&quot;), Password: cfg.GetString(&quot;password&quot;), DBType: cfg.GetString(&quot;dbType&quot;), &#125;&#125;var DatabaseConfig = new(Database) 数据库的配置修改为： mysql.go 修改如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package dbimport ( &quot;bytes&quot; &quot;chain-web/user-web/config&quot; _ &quot;github.com/go-sql-driver/mysql&quot; &quot;strconv&quot;)import &quot;github.com/jinzhu/gorm&quot;var SqlDB *gorm.DBvar ( DbType string Host string Port int Name string Username string Password string)func SetUp() &#123; //创建一个数据库的连接 var err error DbType = config.DatabaseConfig.DBType Host = config.DatabaseConfig.Host Port = config.DatabaseConfig.Port Name = config.DatabaseConfig.Name Username = config.DatabaseConfig.Username Password = config.DatabaseConfig.Password var conn bytes.Buffer conn.WriteString(Username) conn.WriteString(&quot;:&quot;) conn.WriteString(Password) conn.WriteString(&quot;@tcp(&quot;) conn.WriteString(Host) conn.WriteString(&quot;:&quot;) conn.WriteString(strconv.Itoa(Port)) conn.WriteString(&quot;)&quot;) conn.WriteString(&quot;/&quot;) conn.WriteString(Name) conn.WriteString(&quot;?charset=utf8&amp;parseTime=True&amp;loc=Local&amp;timeout=1000ms&quot;) SqlDB, err = gorm.Open(DbType, conn.String()) SqlDB.LogMode(true) if err != nil &#123; panic(&quot;failed to connect database&quot;) &#125;&#125; 8 微服务的引入。","raw":null,"content":null,"categories":[{"name":"go","slug":"go","permalink":"http://yoursite.com/categories/go/"}],"tags":[{"name":"web开发","slug":"web开发","permalink":"http://yoursite.com/tags/web开发/"}]},{"title":"开发工具整理","slug":"开发工具整理","date":"2020-07-10T01:34:00.000Z","updated":"2021-08-23T08:29:40.711Z","comments":true,"path":"2020/07/10/开发工具整理/","link":"","permalink":"http://yoursite.com/2020/07/10/开发工具整理/","excerpt":"","text":"远程联调，内网穿透内网穿透的好处是有利于远程协作，可以让别人看到你写的东西，而且不用服务器部署，节约成本，更利于快速的变更。 frpfrp 目前开源，可以自己搭建服务器，和客户端，好处是可以固定ip ngrok:ngrok 的好处是不需要配置服务端，可以通过他自己的网络进行网络穿透，但外网ip是随机的，如果需要固定ip，则需要付费。 基本的启动命令 1/Users/apple/go/src/ngrok http 127.0.0.1:8872 开发工具idea 插件 jclasslib bytecode viewer : 可以查看javap编译后的字节码变量，查看哪些是放在栈里面的。 lombok ：不用说了，减少setter，getter的神器。 适合开发人员的压测工具 wrk命令行工具，适合开发人员自我测试用 jmeter中量级工具，有ui工具可以用。 ab ：命令行工具，安装过于复杂","raw":null,"content":null,"categories":[],"tags":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/tags/工具/"}]},{"title":"cacheline和伪共享问题","slug":"cacheline和伪共享问题","date":"2020-07-06T16:17:00.000Z","updated":"2021-08-23T08:29:40.704Z","comments":true,"path":"2020/07/07/cacheline和伪共享问题/","link":"","permalink":"http://yoursite.com/2020/07/07/cacheline和伪共享问题/","excerpt":"","text":"查看缓存行的大小。1cat /sys/devices/system/cpu/cpu1/cache/index0/coherency_line_size 验证cacheline的存在。cacheline 的代码验证,如下所示的代码，按照正常的理解我们应该认为第一个循环和第二个循环的效率应该是一样的。 123456789public static void main(String[] args) &#123; int[] arr = new int[64 * 1024 * 1024]; long start = System.currentTimeMillis(); for (int i = 0; i &lt; arr.length; i++) arr[i] *= 3; System.out.println(&quot;第一个循环=&quot;+(System.currentTimeMillis() - start)); start = System.currentTimeMillis(); for (int i = 0; i &lt; arr.length; i += 16) arr[i] *= 3; System.out.println(&quot;第二个循环=&quot;+(System.currentTimeMillis() - start)); &#125; 上述的循环，循环2做了循环1/16 的工作，但消耗的时间基本等同 原因对于现代的操作系统而言，每次获取缓存数据到L1缓存，不是以一个字节一个字节去获取，而是一次性获取一个块(cache line)，在64位操作系统里面一个cache line大小为64byte。一个int 4bytes，所以读取16个和一次读取读取一个效率上是一样的。 伪共享问题出现的原因如果 两个变量 （a,b） 同时在一个 Cache Line 中，处理器A修改了变量a ，那么处理器B中，这个 CacheLine 失效了，这个时候如果处理器B修改了变量b的话，就必须先提交处理器A的缓存，然后处理器B再去主存中读取数据！这样就出现了问题，a和b在两个处理器上被修改，本应该是一个并行的操作，但是由于缓存一致性，却成为了串行！这样会严重的影响并发的性能！ 解决伪共享的方案一填充long字节。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package concurrent.falseshare;/** * 伪共享问题： * @author xiaohei * @create 2020-06-28 上午11:18 **/public class FalseShareTest implements Runnable &#123; public static int NUM_THREADS = 4; public final static long ITERATIONS = 500L * 1000L * 1000L; private final int arrayIndex; private static VolatileLong[] longs; public static long SUM_TIME = 0l; public FalseShareTest(final int arrayIndex) &#123; this.arrayIndex = arrayIndex; &#125; public static void main(final String[] args) throws Exception &#123; Thread.sleep(10000); for(int j=0; j&lt;10; j++)&#123; System.out.println(j); NUM_THREADS=Runtime.getRuntime().availableProcessors(); longs = new VolatileLong[NUM_THREADS]; for (int i = 0; i &lt; longs.length; i++) &#123; longs[i] = new VolatileLong(); &#125; final long start = System.nanoTime(); runTest(); final long end = System.nanoTime(); SUM_TIME += end - start; &#125; System.out.println(&quot;平均耗时：&quot;+SUM_TIME/10); &#125; private static void runTest() throws InterruptedException &#123; //开启线程 Thread[] threads = new Thread[NUM_THREADS]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseShareTest(i)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; longs[arrayIndex].value = i; &#125; &#125; public final static class VolatileLong &#123; public volatile long value = 0L; //对所有线程可见 /** * 对象头信息占用8到12个字节 * 解决伪共享问题的关键 * 缓存行通常是 64 字节（基于 64 字节，其他长度的如 32 字节） * */ public long p1, p2, p3, p4, p5, p6; //屏蔽此行 &#125;&#125; 解决伪共享方案二 Contended注解jdk 1.8 之后有效 资料12345https://www.cnblogs.com/diegodu/p/9340243.htmlcnblogs.com/cyfonly/p/5800758.htmlhttps://blog.csdn.net/zhanglong_4444/article/details/93631216http://igoro.com/archive/gallery-of-processor-cache-effects/https://blog.csdn.net/u010983881/article/details/82704733","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"cache","slug":"cache","permalink":"http://yoursite.com/tags/cache/"},{"name":"高并发","slug":"高并发","permalink":"http://yoursite.com/tags/高并发/"}]},{"title":"spring boot 工作原理","slug":"spring-boot-工作原理","date":"2020-06-26T06:46:00.000Z","updated":"2021-08-23T08:29:40.709Z","comments":true,"path":"2020/06/26/spring-boot-工作原理/","link":"","permalink":"http://yoursite.com/2020/06/26/spring-boot-工作原理/","excerpt":"","text":"spring boots 的工程开发 一般性我们只需要如下图配置就OK了 为什么这么配置之后spring boots就能启动了？看一下 SpringBootsApplication 核心的代码基本就在 @EnableAutoConfiguration里面","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://yoursite.com/tags/spring-boot/"}]},{"title":"spring cloud gateway 框架整理","slug":"spring-cloud-gateway-框架整理","date":"2020-06-21T07:32:00.000Z","updated":"2021-08-23T08:29:40.709Z","comments":true,"path":"2020/06/21/spring-cloud-gateway-框架整理/","link":"","permalink":"http://yoursite.com/2020/06/21/spring-cloud-gateway-框架整理/","excerpt":"","text":"配置文件配置12345678910spring: cloud: gateway: routes: - id: fiction-server uri: lb://xd-fiction-server predicates: - Path=/book/** # filters: - PrefixPath=/client # GatewayFilter，可以配置多个 上面的配置会先通过 PathRoutePredicateFactory 查到 小说服务。然后通过PrefixPath 查找 小说服务的 /client/book/** 接口 各个接口简单说明Predicategateway的入口类，主要是通过头信息，参数，时间和路径查找对应的服务 GatewayFilter配置在配置文件的filter的的接口类。 GlobalFilter全局过滤器，默认所有的route都会通过该过滤器执行，一般实现该接口都会实现 orderd 接口，过滤器的执行顺序需要通过order去判断先后顺序，需要是指责链模式,具体可以查找FilteringWebHandler，改类给出了详细的实现方式，GlobalFilter和GatewayFilter虽然继承不同的接口，其实最终还是同一个地方用到。 FilteringWebHandler过滤器执行,把全局过滤器和局部过滤器按照orderd顺序排序执行。 RoutePredicateHandlerMapping gateway的核心执行类， 先通过Predicate查找对应的router 123456789101112131415161718192021222324252627282930313233protected Mono&lt;Route&gt; lookupRoute(ServerWebExchange exchange) &#123; return this.routeLocator.getRoutes() // individually filter routes so that filterWhen error delaying is not a // problem .concatMap(route -&gt; Mono.just(route).filterWhen(r -&gt; &#123; // add the current route we are testing exchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId()); return r.getPredicate().apply(exchange); &#125;) // instead of immediately stopping main flux due to error, log and // swallow it .doOnError(e -&gt; logger.error( &quot;Error applying predicate for route: &quot; + route.getId(), e)) .onErrorResume(e -&gt; Mono.empty())) // .defaultIfEmpty() put a static Route not found // or .switchIfEmpty() // .switchIfEmpty(Mono.&lt;Route&gt;empty().log(&quot;noroute&quot;)) .next() // TODO: error handling .map(route -&gt; &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Route matched: &quot; + route.getId()); &#125; validateRoute(route, exchange); return route; &#125;); /* * TODO: trace logging if (logger.isTraceEnabled()) &#123; * logger.trace(&quot;RouteDefinition did not match: &quot; + routeDefinition.getId()); &#125; */&#125; 然后通过 router查找到对应的FilteringWebHandler 123456789101112131415161718192021222324252627protected Mono&lt;?&gt; getHandlerInternal(ServerWebExchange exchange) &#123; // don&apos;t handle requests on management port if set and different than server port if (this.managementPortType == DIFFERENT &amp;&amp; this.managementPort != null &amp;&amp; exchange.getRequest().getURI().getPort() == this.managementPort) &#123; return Mono.empty(); &#125; exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange) // .log(&quot;route-predicate-handler-mapping&quot;, Level.FINER) //name this .flatMap((Function&lt;Route, Mono&lt;?&gt;&gt;) r -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); if (logger.isDebugEnabled()) &#123; logger.debug( &quot;Mapping [&quot; + getExchangeDesc(exchange) + &quot;] to &quot; + r); &#125; exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); return Mono.just(webHandler); &#125;).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -&gt; &#123; exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); if (logger.isTraceEnabled()) &#123; logger.trace(&quot;No RouteDefinition found for [&quot; + getExchangeDesc(exchange) + &quot;]&quot;); &#125; &#125;)));&#125; 至于后面其实是基于Spring webflux做的一些事情，基本上有问题，入口类从这里找起会比较合适。 RouteDefinitionRouteLocator路由加载器，请求的时候会加载一边数据。如果需要知道Predicate 可以加载一个还是多个，是如何加载的，可以看下里面的代码。","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"http://yoursite.com/tags/spring-cloud/"}]},{"title":"基于docker搭建mongodb","slug":"基于docker搭建mongodb","date":"2020-05-29T12:47:00.000Z","updated":"2021-08-23T08:29:40.711Z","comments":true,"path":"2020/05/29/基于docker搭建mongodb/","link":"","permalink":"http://yoursite.com/2020/05/29/基于docker搭建mongodb/","excerpt":"","text":"mongo集群搭建第一步创建 docker-compose.yml文件docker-compose.yml: 1234567891011121314151617181920212223version: &apos;3&apos;services: rs1: image: mongo:latest container_name: &quot;mongo-rs-1&quot; network_mode: &quot;host&quot; volumes: - /data/mongodb/rs1:/data/db command: mongod --port 57017 --dbpath /data/db --replSet mongoreplset rs2: image: mongo:latest container_name: &quot;mongo-rs-2&quot; network_mode: &quot;host&quot; volumes: - /data/mongodb/rs2:/data/db command: mongod --port 57018 --dbpath /data/db --replSet mongoreplset rs3: image: mongo:latest container_name: &quot;mongo-rs-3&quot; network_mode: &quot;host&quot; volumes: - /data/mongodb/rs3:/data/db command: mongod --port 57019 --dbpath /data/db --replSet mongoreplset host 文件配置123127.0.0.1 mongo-rs-3127.0.0.1 mongo-rs-2127.0.0.1 mongo-rs-1 network的选择，为什么是host 而不是 bridge主要是如果是brigge 模式，外网访问也会调用mongodb的心跳，但因为两边网络不通，会导致客户端认为mongodb的集群是不成功的。先要配置host文件，然后再启动docker，因为host配置默认会复制hosts文件到容器里面。 使用 docker-compose 组件启动集群1docker-compose up -d 如果没有安装 docker-compose组件 1yum install docker-compose 集群replica set 配置进入集群主节点1docker exec -it mongo-rs-1 mongo --port=57017 添加集群配置123rs.initiate()rs.add(&quot;mongo-rs-2:57018&quot;)rs.add(&quot;mongo-rs-2:57018&quot;) 默认情况下，主节点host是 是默认的域名，不会是mongo-rs-1，所以需要重新配置关闭主节点： 1docker stop mongo-rs-1 这时候备份节点有一个会变成主节点,在新的主节点操作 123docker exec -it mongo-rs-2 mongo --port=57018rs.remove(&quot;默认host:57017&quot;) 启动老的主节点，这时候这是独立节点，在新的主节点操作 1rs.add(&quot;mongo-rs-1:57017&quot;) 参考资料1http://bazingafeng.com/2017/06/19/create-mongodb-replset-cluster-using-docker/","raw":null,"content":null,"categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"mongo","slug":"mongo","permalink":"http://yoursite.com/tags/mongo/"}]},{"title":"BPlugsTree-java实现","slug":"BPlugsTree-java实现","date":"2020-04-29T14:47:00.000Z","updated":"2021-08-23T08:29:40.703Z","comments":true,"path":"2020/04/29/BPlugsTree-java实现/","link":"","permalink":"http://yoursite.com/2020/04/29/BPlugsTree-java实现/","excerpt":"","text":"背景b+ 树，目前删除还不是很完善，主要是为了搞明白h2数据库预先打下基础，后面会开始通过这个然后比对h2是如何实现这块的逻辑。 应用的数据库h2，mysql， b+树的图解：![](/images/b 树最大值索引.jpg) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683package tree;/** * 一个m阶的B+树包含的特性 * 1.任意非叶子结点最多有M个子节点；且M&gt;2； * 2.除根结点以外的非叶子结点至少有 M/2个子节点； * 3.根结点至少有2个子节点； * 4.除根节点外每个结点存放至少M/2和至多M个关键字；（至少2个关键字） * 5.非叶子结点的子树指针与关键字个数相同； * 6.所有结点的关键字：K[1], K[2], …, K[M]；且K[i] &lt; K[i+1]； * 7.非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树； * 8.所有叶子结点位于同一层； * 9.为所有叶子结点增加一个链指针； * 10.所有value都在叶子结点出现； * 扩展思考 B*树的实现，R树的实现 * B+树有两种实现，最大值和最小值两种， 目前实现的是最大key链接 * * @author xiaohei * @create 2020-04-21 下午2:23 **/public class BPlugsTree&lt;K extends Comparable, V&gt; &#123; /** * 根节点 */ private Node&lt;K, V&gt; root; /** * */ private Leaf&lt;K, V&gt; first; /** * 每个块包含多少数据 */ private int m; /** * 这个树的深度 */ private int h; /** * 树拥有的数据 */ private int size; public BPlugsTree(int m) &#123; this.m = m; this.size = 0; root = new Leaf&lt;K, V&gt;(m); &#125; public V get(K k) &#123; return root.search(k); &#125; public Integer size() &#123; return size; &#125; public boolean isEmpty() &#123; return size == 0; &#125; /** * 删除数据需要的考虑的问题 * 1：删除k等于非叶子节点的值，删除的是叶子节点的最大值，需要把叶子节点的新的最大值赋值给父亲节点。 * 2：当叶子节点小于m/2的时候，考虑从后面那个节点大于m/2 ，则借取（为什么不从前面那个借，因为父节点按照最大值索引，找前面借，会导致父节点的变换。） * 3：但儿子节点因为节点 * * @param k * @return */ public V delete(K k) &#123; //TODO 递归删除 if (k == null || size == 0) &#123; return null; &#125; size--; return root.delete(k, root); &#125; /** * 添加新的节点 * * @param k * @param v */ public void insert(K k, V v) &#123; //如果返回了新的root节点，则把原来的根节点替换为新的节点。 Node node = root.insert(k, v); if (node != null) &#123; this.root = node; &#125; size++; &#125; /** * 节点，叶子节点和非叶子节点共有方法抽取 */ abstract static class Node&lt;K extends Comparable, V&gt; &#123; /** * 该节点的父亲节点 */ protected NoneLeaf&lt;K, V&gt; parent; /** * 一个块包含多个kv */ protected Object[] keys; /** * 阶数，一个node最多包含几个数，最少不能少于m/2 */ protected int m; /** * 当前包含了多少数据 */ protected int size; /** * 添加新的数据，有可能产生新的root节点 * * @param k * @param v * @return 返回b树的root节，当没有新的父亲节点产生的时候，返回空 */ public abstract Node&lt;K, V&gt; insert(K k, V v); /** * 查找k 对应 的value * * @param k * @return */ public abstract V search(K k); /** * 删除一条数据 * * @param k * @return */ public abstract V delete(K k, Node root); /** * 是否可以合并节点 * * @param node * @return */ protected boolean canMerge(Node&lt;K, V&gt; node) &#123; return node != null &amp;&amp; node.parent == this.parent &amp;&amp; (node.size &lt;= m / 2 || node.size &lt;= 2); &#125; /** * 是否可以借数据 * * @param node * @return */ protected boolean canBorrowEntry(Node&lt;K, V&gt; node) &#123; return node != null &amp;&amp; node.parent == this.parent &amp;&amp; node.size &gt; m / 2 &amp;&amp; node.size &gt; 2; &#125; &#125; /** * 叶子节点 保存 索引字段和数据 */ static class Leaf&lt;K extends Comparable, V&gt; extends Node&lt;K, V&gt; &#123; /** * 存入数据的key值 */ private Object[] values; /** * 前一个叶子节点 */ private Leaf&lt;K, V&gt; pre; /** * 后一个叶子节点 */ private Leaf&lt;K, V&gt; next; Leaf(int m) &#123; this.keys = new Object[m]; this.values = new Object[m]; &#125; /** * 添加新的节点， * * @param k * @param v * @return 返回b树的root节点，当没有新的父亲节点产生的时候，返回空 */ public Node&lt;K, V&gt; insert(K k, V v) &#123; int i = 0; for (; i &lt; size; ) &#123; // 相等，说明key已经存在，不做处理，或者把value直接覆盖 if (k.compareTo(keys[i]) == 0) &#123; return null; &#125; //当k 小于某个排序的值的时候，说明它的位置就是i ，后面的数据需要往后 if (k.compareTo(keys[i]) &lt; 0) &#123; break; &#125; i++; &#125; this.size = size + 1; Object[] newKeys = new Object[size]; Object[] newValues = new Object[size]; newKeys[i] = k; newValues[i] = v; if (size == 1) &#123; this.keys = newKeys; this.values = newValues; return null; &#125; System.arraycopy(keys, 0, newKeys, 0, i); System.arraycopy(values, 0, newValues, 0, i); int copyLength = size - (i + 1); if (copyLength &gt; 0) &#123; System.arraycopy(keys, i, newKeys, i + 1, copyLength); System.arraycopy(values, i, newValues, i + 1, copyLength); &#125; this.keys = newKeys; this.values = newValues; //当 数组的长度超过m的时候，需要分裂成两个Node节点。并把该节点的最大值生成一个父节点，如果还需要分裂，再次分裂 if (size &gt; m) &#123; int newSize = size / 2; if (this.parent == null) &#123; this.parent = new NoneLeaf(m); &#125; this.keys = new Object[m]; this.values = new Object[m]; this.size = newSize; /** 原来节点key value 重新赋值 */ System.arraycopy(newKeys, 0, this.keys, 0, newSize); System.arraycopy(newValues, 0, this.values, 0, newSize); /** 前后节点赋值 */ Leaf oldNext = this.next; Leaf&lt;K, V&gt; newLeaf = new Leaf&lt;K, V&gt;(m); this.next = newLeaf; //老的右节点赋值给新的接口的next属，因为 this &lt; newLeaf &lt; this.next newLeaf.next = oldNext; newLeaf.pre = this; /** 新节点key赋值 */ newLeaf.size = newKeys.length - newSize; System.arraycopy(newKeys, newSize, newLeaf.keys, 0, newLeaf.size); System.arraycopy(newValues, newSize, newLeaf.values, 0, newLeaf.size); return parent.insert(this, newLeaf); &#125; return null; &#125; public V search(K k) &#123; for (int i = 0; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) == 0) &#123; return (V) values[i]; &#125; &#125; return null; &#125; public V delete(K k, Node root) &#123; /** * TODO * if 根目录 * 直接删除数据，设置高度为0 * if size &gt; m/2 : * 删除数据 * if (size &lt;= m/2 || size==2)&amp;&amp;next.size &gt; m/2 : * 从后面的节点借一个数据。 * 设置当前节点的父亲节点的该节点的最大值。 * else if (size &gt;= m/2 || size==2)&amp;&amp;pre.size &gt; m/2 : * 从前面借一个数据。 * 设置前一个节点的父亲节点前一个节点的最大值 * else: * 与前一个节点或者后面一个节点合并。 */ if (this == root || (size &gt; m / 2 &amp;&amp; size &gt; 2)) &#123; int i = 0; for (; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) == 0) &#123; return remove(i).getV(); &#125; &#125; &#125; else &#123; //当node的keys不足m/2时,找左节点要数据 if (canBorrowEntry(pre)) &#123; int i = 0; for (; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) == 0) &#123; //被删除的值 V removeValue = (V) this.values[i]; //把左node的最大一位移动这个Node的第一位 Entry&lt;K, V&gt; entry = pre.getAndRemoveLast(); pre.resetParentKey(); Object[] newKey = new Object[size]; Object[] newValue = new Object[size]; newKey[0] = entry.getK(); newValue[0] = entry.getV(); //第一位已经被左边节点占，所以新数组从第一位开始拷贝 System.arraycopy(this.keys, 0, newKey, 1, i); System.arraycopy(this.values, 0, newValue, 1, i); if (size &gt; i + 1) &#123; int len = size - i - 1; System.arraycopy(this.keys, i, newKey, i + 1, len); System.arraycopy(this.values, i, newValue, i + 1, len); &#125; return removeValue; &#125; &#125; &#125; else if (canBorrowEntry(next)) &#123; int i = 0; for (; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) == 0) &#123; //被删除的值 V removeValue = (V) this.values[i]; //把左node的最大一位移动这个Node的第一位 Entry&lt;K, V&gt; entry = next.getAndRemoveFirst(); this.resetParentKey(); Object[] newKey = new Object[size]; Object[] newValue = new Object[size]; newKey[size - 1] = entry.getK(); newValue[size - 1] = entry.getV(); //第一位已经被左边节点占，所以新数组从第一位开始拷贝 System.arraycopy(this.keys, 0, newKey, 0, i); System.arraycopy(this.values, 0, newValue, 0, i); if (size &gt; i + 1) &#123; int len = size - i - 1; System.arraycopy(this.keys, i, newKey, i, len); System.arraycopy(this.values, i, newValue, i, len); &#125; return removeValue; &#125; &#125; &#125; else if (canMerge(pre)) &#123; int i = 0; for (; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) == 0) &#123; //先删除需要删除的节点 remove(i); Object[] keys = new Object[pre.size + this.size]; System.arraycopy(pre.keys, 0, keys, 0, pre.size); System.arraycopy(this.keys, 0, keys, pre.size, this.size); Object[] values = new Object[pre.size + this.size]; System.arraycopy(pre.values, 0, values, 0, pre.size); System.arraycopy(this.values, 0, values, pre.size, this.size); this.keys = keys; this.values = values; /** * 和前节点合并的时候，把前节点的数据放置到当前节点，这样不用改变当前节点对应父节点的值 */ Leaf&lt;K, V&gt; removeNode = this.pre; if (pre.pre != null) &#123; pre.pre.next = this; this.pre = pre.pre; &#125; //父类对象删除对删除node的引用 if (parent != null) &#123; parent.remove(removeNode); &#125; removeNode.pre = null; removeNode.next = null; removeNode = null; &#125; &#125; &#125; else if (canMerge(next)) &#123; int i = 0; for (; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) == 0) &#123; //删除节点 remove(i); //和前节点合并 Object[] keys = new Object[next.size + this.size]; System.arraycopy(this.keys, 0, keys, 0, size); System.arraycopy(next.keys, 0, keys, size, next.size); Object[] values = new Object[pre.size + this.size]; System.arraycopy(this.values, i, values, 0, size); System.arraycopy(next.values, 0, values, size, next.size); this.next.keys = keys; this.next.values = values; //与兄弟节点的操作 Leaf removeNode = this; if (next != null) &#123; next.pre = this.pre; if (this.pre != null) &#123; this.pre.next = this.next; &#125; &#125; //父类对象操作 删除当前节点的应用 if (parent != null) &#123; parent.remove(this); &#125; this.pre = null; this.next = null; &#125; &#125; &#125; &#125; return null; &#125; /** * 删除数据 * * @param i * @return */ private Entry&lt;K, V&gt; remove(Integer i) &#123; Entry&lt;K, V&gt; entry = new Entry(this.keys[i], this.values[i]); //减少数据总数 size--; Object[] newKey = new Object[size]; Object[] newValue = new Object[size]; System.arraycopy(this.keys, 0, newKey, 0, i); System.arraycopy(this.values, 0, newValue, 0, i); int len = size - i; System.arraycopy(this.keys, i + 1, newKey, i, len); System.arraycopy(this.values, i + 1, newValue, i, len); this.keys = newKey; this.values = newValue; return entry; &#125; /** * 重置中间节点的对应这个节点的关键字 */ public void resetParentKey() &#123; if (this.parent != null) &#123; parent.resetKey(this); &#125; &#125; /** * 获取最后一个节点数据给后面那个节点 * * @return */ private Entry&lt;K, V&gt; getAndRemoveLast() &#123; return remove(size - 1); &#125; /** * 获取next节点的第一个数据给前面那个节点。 * * @return */ private Entry&lt;K, V&gt; getAndRemoveFirst() &#123; return remove(0); &#125; &#125; /** * 获取 kv 对象 * * @param &lt;K&gt; * @param &lt;V&gt; */ static class Entry&lt;K, V&gt; &#123; private K k; private V v; public Entry(K k, V v) &#123; this.k = k; this.v = v; &#125; public K getK() &#123; return k; &#125; public V getV() &#123; return v; &#125; &#125; /** * 非叶子节点 */ static class NoneLeaf&lt;K extends Comparable, V&gt; extends Node&lt;K, V&gt; &#123; /** * 子节点，可能是叶子节点，也有可能是非叶子节点 */ private Node&lt;K, V&gt;[] children; public NoneLeaf(int m) &#123; this.keys = new Object[m]; this.children = new Node[m]; &#125; /** * 当 子节点的最大值改变之后需要递归变更父节点的关键字 * * @param child */ private void resetKey(Node child) &#123; for (int i = 0; i &lt; size; i++) &#123; if (children[i] == child) &#123; this.keys[i] = child.keys[child.size - 1]; &#125; if (i == size - 1) &#123; //如果更新的最后一个数值，递归更新父亲节点 resetKey(this); &#125; &#125; &#125; /** * 删除子节点，当两个节点合并的时，会去掉对一个node的引用 * * @param child */ private void remove(Node child) &#123; for (int i = 0; i &lt; size; i++) &#123; if (children[i] == child) &#123; remove(i); //TODO 删除之后，判断是否需要合并 &#125; &#125; &#125; private void updateRemove(Node root) &#123; //如果size 大于 m/2 不做处理 if (this.size &gt; 2 &amp;&amp; this.size &gt; m / 2) &#123; return; &#125; &#125; /** * 删除数据，生成一个新的数组放新的数据组 * * @param i */ private void remove(int i) &#123; size--; Object[] newKey = new Object[size]; Node[] newValue = new Node[size]; System.arraycopy(this.keys, 0, newKey, 0, i); System.arraycopy(this.children, 0, newValue, 0, i); int len = size - i; System.arraycopy(this.keys, i + 1, newKey, i, len); System.arraycopy(this.children, i + 1, newValue, i, len); this.keys = newKey; this.children = newValue; &#125; /** * @param left 左节点 是本来的节点，所以children的指向不会变 * @param right 大节点 是新的节点，所以child的指向需要新增 * 为什么叫left k 而不是加right，因为 right最大值已经是插入的时候做了一次替换，所以没有必要再加。 */ private Node&lt;K, V&gt; insert(Node left, Node right) &#123; K k = (K) left.keys[left.size - 1]; if (this.size == 0) &#123; children = new Node[m]; children[0] = left; children[1] = right; left.parent = this; right.parent = this; keys = new Object[2]; keys[0] = k; keys[1] = right.keys[right.size - 1]; this.size += 2; return this; &#125; int i = 0; for (; i &lt; size; i++) &#123; // 相等，说明key已经存在，不做处理，或者把value直接覆盖 if (k.compareTo(keys[i]) == 0) &#123; return null; &#125; //当k 小于某个排序的值的时候，说明它的位置就是i ，后面的数据需要往后 if (k.compareTo(keys[i]) &lt; 0) &#123; break; &#125; &#125; this.size = size + 1; Object[] newKeys = new Object[size]; Node[] newChildren = new Node[size + 1]; newKeys[i] = k; //设置新节点的父亲节点为该节点 right.parent = this; newChildren[i + 1] = right; if (size == 1) &#123; keys = newKeys; return null; &#125; System.arraycopy(keys, 0, newKeys, 0, i); System.arraycopy(children, 0, newChildren, 0, i + 1); int copyLength = size - (i + 1); if (copyLength &gt; 0) &#123; System.arraycopy(keys, i, newKeys, i + 1, copyLength); &#125; copyLength = size - (i + 2); if (copyLength &gt; 0) &#123; System.arraycopy(children, i + 1, newChildren, i + 2, copyLength); &#125; this.keys = newKeys; this.children = newChildren; //当 数组的长度超过m的时候，需要分裂成两个Node节点。并把该节点的最大值生成一个父节点，如果还需要分裂，再次分裂 if (size &gt; m) &#123; int newSize = size / 2; if (this.parent == null) &#123; this.parent = new NoneLeaf(m); &#125; this.keys = new Object[m]; this.size = newSize; System.arraycopy(newKeys, 0, this.keys, 0, newSize); System.arraycopy(newChildren, 0, this.children, 0, newSize + 1); NoneLeaf&lt;K, V&gt; newLeaf = new NoneLeaf&lt;K, V&gt;(m); newLeaf.size = newKeys.length - newSize; System.arraycopy(newKeys, newSize, newLeaf.keys, 0, newLeaf.size); System.arraycopy(newChildren, newSize, newLeaf.children, 0, newLeaf.size); return parent.insert(this, newLeaf); &#125; return null; &#125; public Node&lt;K, V&gt; insert(K k, V v) &#123; /** * 首先查找k 该k 是否是小于等于keys[i], * 是：就取child[i] ，一致递归到leaf 节点，进行实际插入操作。 */ for (int i = 0; i &lt; size; i++) &#123; if (k.compareTo(keys[i]) &lt;= 0) &#123; return children[i].insert(k, v); &#125; &#125; /** * key的值为子节点的最大值 * 如果该值比最大值还要大，替换最大值为插入值，然后插入最大的子节点。 */ keys[size - 1] = k; return children[size - 1].insert(k, v); &#125; /** * 典型的二叉树查找规则，从上面之下，和跳表的规则类似 * * @param k * @return */ public V search(K k) &#123; for (int i = 0; i &lt; size; i++) &#123; //从最小值开始比较 if (k.compareTo(keys[i]) &lt;= 0) &#123; return children[i].search(k); &#125; &#125; return children[size].search(k); &#125; /** * 删除的时候需要注意的问题，删除最大值，因为父节点是通过最大值来对应查找子节点，如果不做同步，有可能导致查找不准确 * 所以在这个情况下应该先删除子节点的最大值，然后把新的最大值传递给父节点。 * * @param k * @return */ public V delete(K k, Node root) &#123; for (int i = 0; i &lt; size; i++) &#123; //从最小值开始比较 if (k.compareTo(keys[i]) &lt;= 0) &#123; return children[i].delete(k, root); &#125; &#125; return null; &#125; &#125;&#125; 测试用例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package tree;import org.junit.jupiter.api.Assertions;import org.junit.jupiter.api.Test;class BPlugsTreeTest &#123; public static void main(String[] args)&#123; int desc = 0; int[] src=&#123;-1,0,1,2&#125;; int i=0; for (; i &lt; src.length; ) &#123; //当k 小于某个排序的值的时候，说明它的位置就是i ，后面的数据需要往后 if (desc&lt;=src[i]) &#123; break; &#125; i++; &#125; System.out.println(i); &#125; @Test public void testSimpleDelete()&#123; BPlugsTree&lt;Integer, String&gt; bPlugsTree = new BPlugsTree(4); bPlugsTree.insert(1, &quot;test 1&quot;); Assertions.assertEquals(bPlugsTree.get(1),&quot;test 1&quot;); bPlugsTree.delete(1); Assertions.assertTrue(bPlugsTree.isEmpty()); &#125; @Test public void testDeleteMerge()&#123; BPlugsTree&lt;Integer, String&gt; bPlugsTree = new BPlugsTree(4); bPlugsTree.insert(1, &quot;test 1&quot;); bPlugsTree.insert(2, &quot;test 2&quot;); bPlugsTree.insert(3, &quot;test 3&quot;); bPlugsTree.insert(4, &quot;test 4&quot;); bPlugsTree.insert(5, &quot;test 5&quot;); bPlugsTree.insert(6, &quot;test 6&quot;); bPlugsTree.insert(7, &quot;test 7&quot;); bPlugsTree.insert(8, &quot;test 8&quot;); bPlugsTree.insert(9, &quot;test 9&quot;); bPlugsTree.insert(10, &quot;test 10&quot;); bPlugsTree.insert(11, &quot;test 11&quot;); bPlugsTree.insert(12, &quot;test 12&quot;); bPlugsTree.insert(13, &quot;test 13&quot;); bPlugsTree.insert(14, &quot;test 14&quot;); bPlugsTree.insert(15, &quot;test 15&quot;); bPlugsTree.insert(16, &quot;test 16&quot;); bPlugsTree.insert(17, &quot;test 17&quot;); bPlugsTree.insert(18, &quot;test 18&quot;); bPlugsTree.insert(19, &quot;test 19&quot;); bPlugsTree.insert(20, &quot;test 20&quot;); bPlugsTree.delete(3); Assertions.assertEquals(20,bPlugsTree.size()); &#125; @Test public void testFistInsert() &#123; //建立一个4阶的b+树 BPlugsTree&lt;Integer, String&gt; bPlugsTree = new BPlugsTree(4); bPlugsTree.insert(1, &quot;test 1&quot;); Assertions.assertEquals(bPlugsTree.get(1),&quot;test 1&quot;); &#125; /** * 测试第一次分裂，因为一个块超出阶数，所以需要生成两个同深度的节点，父节点需要插入这两个节点的关系，有可能又导致分裂 */ @Test public void testFistSplit() &#123; BPlugsTree&lt;String, String&gt; bPlugsTree = new BPlugsTree(4); bPlugsTree.insert(&quot;1&quot;, &quot;test 1&quot;); bPlugsTree.insert(&quot;2&quot;, &quot;test 2&quot;); bPlugsTree.insert(&quot;3&quot;, &quot;test 3&quot;); bPlugsTree.insert(&quot;4&quot;, &quot;test 4&quot;); bPlugsTree.insert(&quot;5&quot;, &quot;test 5&quot;); Assertions.assertEquals(bPlugsTree.get(&quot;5&quot;),&quot;test 5&quot;); &#125; @Test public void testDoubleSplit()&#123; BPlugsTree&lt;Integer, String&gt; bPlugsTree = new BPlugsTree(4); bPlugsTree.insert(1, &quot;test 1&quot;); bPlugsTree.insert(2, &quot;test 2&quot;); bPlugsTree.insert(3, &quot;test 3&quot;); bPlugsTree.insert(4, &quot;test 4&quot;); bPlugsTree.insert(5, &quot;test 5&quot;); bPlugsTree.insert(6, &quot;test 6&quot;); bPlugsTree.insert(7, &quot;test 7&quot;); bPlugsTree.insert(8, &quot;test 8&quot;); bPlugsTree.insert(9, &quot;test 9&quot;); bPlugsTree.insert(10, &quot;test 10&quot;); bPlugsTree.insert(11, &quot;test 11&quot;); bPlugsTree.insert(12, &quot;test 12&quot;); bPlugsTree.insert(13, &quot;test 13&quot;); bPlugsTree.insert(14, &quot;test 14&quot;); bPlugsTree.insert(15, &quot;test 15&quot;); bPlugsTree.insert(16, &quot;test 16&quot;); bPlugsTree.insert(17, &quot;test 17&quot;); bPlugsTree.insert(18, &quot;test 18&quot;); bPlugsTree.insert(19, &quot;test 19&quot;); bPlugsTree.insert(20, &quot;test 20&quot;); Assertions.assertEquals(bPlugsTree.get(20),&quot;test 20&quot;); Assertions.assertEquals(20,bPlugsTree.size()); &#125;&#125; 参考资料 1https://zhuanlan.zhihu.com/p/60969786","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"},{"name":"h2","slug":"h2","permalink":"http://yoursite.com/tags/h2/"}]},{"title":"linux内存和cpu查看","slug":"linux内存和cpu查看","date":"2020-04-09T13:07:00.000Z","updated":"2021-09-18T12:34:03.818Z","comments":true,"path":"2020/04/09/linux内存和cpu查看/","link":"","permalink":"http://yoursite.com/2020/04/09/linux内存和cpu查看/","excerpt":"","text":"1.CPU占用最多的前10个进程：1ps auxw|head -1;ps auxw|sort -rn -k3|head -10 2.内存消耗最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k4|head -10 3.虚拟内存使用最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k5|head -10 查看 内存信息查看内存的统计信息 1free -h 查看某个进程内存的具体使用信息 1pmap -X pid ###查看文件句柄数 1cat /proc/sys/fs/file-nr 查看tcp连接数 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; 查看oom 信息 1sudo dmesg | grep -i kill | less 123/proc/$PID/oom_adj/proc/$PID/oom_score/proc/$PID/oom_score_adj 1ps -eo pid,comm,pmem --sort -rss | awk &apos;&#123;&quot;cat /proc/&quot;$1&quot;/oom_score&quot; | getline oom; print $0&quot;\\t&quot;oom&#125;&apos; 查看硬盘问题 12345df -lhdu -sh /*du -h --max-depth=0 your_dest_dir/*lsof |grep deletedu|sort -nr|more 查看当前文件夹下文件大小 1ls -htla java应用程序查看内存https://qsli.github.io/2017/12/02/google-perf-tools/","raw":null,"content":null,"categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"数据库开发设计学习","slug":"数据库开发设计学习","date":"2020-03-22T05:48:00.000Z","updated":"2021-08-23T08:29:40.711Z","comments":true,"path":"2020/03/22/数据库开发设计学习/","link":"","permalink":"http://yoursite.com/2020/03/22/数据库开发设计学习/","excerpt":"","text":"系统外知识 1: 操作系统里的Page(页)是固定大小的内存，一般为4k,可以通过命令查找。 数据库主要涉及的知识点1:事务，隔离级别2:MVCC3:多版本存储,每一个版本都是一个B-tree树4:B-treeC-ISAMD-ISAM 事务需要解决的问题12345678910111213141516 原子性:是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 一致性:是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 隔离性:是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性:是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。``` 从某种意义上来说，原子性和一致性 是事务主要需要解决的问题，隔离性是因为一致性的需要而引入的，持久性对于非内存数据库是比较重要的概念。#### 解决的方案日志的REDO/UNDO机制在mysql中，redo日志主要记录数据库中每个页的修改有innodb记录，和binlog是有区别的，binlog是数据库引擎上层的行为。整个详细的方案可以参考下https://www.cnblogs.com/f-ck-need-u/p/9010872.html##### 参考的资料 https://zhuanlan.zhihu.com/p/35574452https://www.cnblogs.com/f-ck-need-u/p/9010872.htmlhttps://www.cnblogs.com/f-ck-need-u/p/9010872.htmlhttps://www.reddit.com/r/Database/comments/27u6dy/how_do_you_build_a_database/ciggal8/http://www.voidcn.com/article/p-huiriupm-sm.htmlhttps://blog.csdn.net/kaixin89/article/details/50738486 ``` 数据存储如果刷盘， 关系型数据库数据的映射。延伸思考1：在数据多写少读的情况下，ps：矿机监控数据库的索引建的越多，更新数据越麻烦，而且排序索引也不会很准。另外一个比如温度之类的，第一页的数据和第二页的数据可能就不一样了。所以最好的方案确实是存的时候一个kv数据，读取的时候，频繁更新的数据如果需要做查询，排序，不适合走索引，适合做镜像。 暂时只写这么多，等看完h2源码再回过来补充资料。","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"rust入门-链表实现","slug":"rust 入门一链表实现","date":"2020-02-27T20:00:00.000Z","updated":"2021-08-23T08:29:40.708Z","comments":true,"path":"2020/02/28/rust 入门一链表实现/","link":"","permalink":"http://yoursite.com/2020/02/28/rust 入门一链表实现/","excerpt":"","text":"关键字段说明：Box ： 12在 Rust 中，所有值默认都是栈分配的。通过创建 Box&lt;T&gt;，可以让值在堆上分配。默认栈上分配，代表了多线程的时候基本不需要考虑锁的问题。 参考资料https://rustwiki.org/zh-CN/rust-by-example/std/box.html","raw":null,"content":null,"categories":[{"name":"rust","slug":"rust","permalink":"http://yoursite.com/categories/rust/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"一致性hash算法","slug":"一致性hash算法","date":"2020-02-24T16:00:00.000Z","updated":"2021-08-23T08:29:40.710Z","comments":true,"path":"2020/02/25/一致性hash算法/","link":"","permalink":"http://yoursite.com/2020/02/25/一致性hash算法/","excerpt":"","text":"主要用途相比简单hash 减少分布式缓存 添加一台机器或者减少一台机器时候，对于缓存路由到新的机子，导致缓存穿透的问题。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/** * 一致性hash算法 */public class ConsistenceHash &#123; /** * 物理节点 */ private List&lt;String&gt; realNode = new ArrayList&lt;String&gt;(); /** * 物理节点对应的虚拟节点。key 对应的是物理节点，value对应的是虚拟节点的hash值 */ private Map&lt;String, List&lt;Integer&gt;&gt; real2VirtualMap = new HashMap(); /** * 虚拟节点数量 */ private int virtualNum = 100; /** * 虚拟节点对应的物理节点,利用红黑树存贮 */ private SortedMap&lt;Integer, String&gt; sortedMap = new TreeMap&lt;Integer, String&gt;(); /** * 添加物理节点 * * @param node */ public void addServer(String node) &#123; realNode.add(node); String vnode = null; int count = 0, i = 0; while (count &lt; virtualNum) &#123; vnode = node + &quot;V_&quot; + i;//生成虚拟节点 int hashValue = getHash(vnode); // 虚拟节点hash value if (!sortedMap.containsKey(hashValue)) &#123; sortedMap.put(hashValue, node); if (!real2VirtualMap.containsKey(node)) &#123; List&lt;Integer&gt; virtualNodes = new ArrayList&lt;Integer&gt;(); real2VirtualMap.put(node, virtualNodes); &#125; real2VirtualMap.get(node).add(hashValue); sortedMap.put(hashValue, node); &#125; count++; &#125; &#125; /** * 删除物理节点，当节点下线或者说节点被移除 * * @param node */ public void removeServer(String node) &#123; // 虚拟节点下园环 List&lt;Integer&gt; virtualNodes = real2VirtualMap.get(node); if (virtualNodes != null &amp;&amp; !virtualNodes.isEmpty()) &#123; for (Integer virtualNode : virtualNodes) &#123; sortedMap.remove(virtualNode); &#125; &#125; //删除物理节点 realNode.remove(node); virtualNodes.remove(node); &#125; /** * 通过 缓存key 获取物理节点 * * @param key * @return */ public String getServer(String key) &#123; int hashValue = getHash(key); SortedMap&lt;Integer, String&gt; subMap = sortedMap.tailMap(hashValue); //圆环当没有比这个hash更大的值的时候，获取最小值，最大值的总结是最小值 if (subMap == null || subMap.isEmpty()) &#123; return sortedMap.get(sortedMap.firstKey()); &#125; return subMap.get(subMap.firstKey()); &#125; /** * 为什么不用 object的hash，因为 自带的hash 散列层度不够,而且有可能是负数 * * @param str * @return */ private static int getHash(String str) &#123; final int p = 1677619; int hash = (int) 2166136261L; for (int i = 0; i &lt; str.length(); i++) &#123; hash = (hash ^ str.charAt(i)) * p; &#125; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; if (hash &lt; 0) &#123; hash = Math.abs(hash); &#125; return hash; &#125; public static void main(String[] args)&#123; ConsistenceHash consistenceHash=new ConsistenceHash(); consistenceHash.addServer(&quot;192.168.1.1&quot;); consistenceHash.addServer(&quot;192.168.1.2&quot;); consistenceHash.addServer(&quot;192.168.1.3&quot;); consistenceHash.addServer(&quot;192.168.1.4&quot;); consistenceHash.addServer(&quot;192.168.1.5&quot;); System.out.println(consistenceHash.getServer(&quot;1&quot;)); System.out.println(consistenceHash.getServer(&quot;2&quot;)); System.out.println(consistenceHash.getServer(&quot;3&quot;)); System.out.println(consistenceHash.getServer(&quot;4&quot;)); System.out.println(consistenceHash.getServer(&quot;5&quot;)); consistenceHash.removeServer(&quot;192.168.1.5&quot;); System.out.println(&quot;after remove &quot;+consistenceHash.getServer(&quot;1&quot;)); System.out.println(&quot;after remove &quot;+consistenceHash.getServer(&quot;2&quot;)); System.out.println(&quot;after remove &quot;+consistenceHash.getServer(&quot;3&quot;)); System.out.println(&quot;after remove &quot;+consistenceHash.getServer(&quot;4&quot;)); System.out.println(&quot;after remove &quot;+consistenceHash.getServer(&quot;5&quot;)); &#125;&#125; 参考资料","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"}]},{"title":"vue 代码解读","slug":"为什么不适用jquery","date":"2020-02-23T16:00:00.000Z","updated":"2021-08-23T08:29:40.710Z","comments":true,"path":"2020/02/24/为什么不适用jquery/","link":"","permalink":"http://yoursite.com/2020/02/24/为什么不适用jquery/","excerpt":"","text":"为什么不用jquey渲染引擎，js引擎解析HTML -&gt; DOM Tree -&gt; Render Tree -&gt; 计算 -&gt; UI引擎渲染 虚拟dom，真实dom虚拟dom ： 1是一个对象，通过diff算法刷选出变更过的对象，渲染真实dom 真实dom：完全增删改，排版重绘虚拟dom：虚拟dom的增删改，diff算法 真实dom增删改+排版重绘","raw":null,"content":null,"categories":[{"name":"node","slug":"node","permalink":"http://yoursite.com/categories/node/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"},{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"}]},{"title":"分布式事务处理方式","slug":"分布式事务处理方式","date":"2020-02-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.710Z","comments":true,"path":"2020/02/02/分布式事务处理方式/","link":"","permalink":"http://yoursite.com/2020/02/02/分布式事务处理方式/","excerpt":"","text":"分布式事务1）什么是数据一致性 在数据有多份副本的情况下，如果网络、服务器或者软件出现故障，会导致部分副本写入成功，部分副本写入失败。这就造成各个副本之间的数据不一致，数据内容冲突。 造成事实上的数据不一致。 2）CAP定理 CAP理论认为在分布式的环境下设计和部署系统时，有3个核心的需求： Consistency，Availability和Partition Tolerance，即CAP。 两阶段提交两个阶段的执行1.请求阶段（commit-request phase，或称表决阶段，voting phase）在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。 2.提交阶段（commit phase）在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。 两阶段提交的缺点1.同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。 2.单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 3.数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。 两阶段提交无法解决的问题当协调者出错，同时参与者也出错时，两阶段无法保证事务执行的完整性。考虑协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 三阶段提交三阶段提交协议在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段拆分成了两步：询问，然后再锁资源，最后真正提交。 执行过程1.CanCommit阶段3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 2.PreCommit阶段Coordinator根据Cohort的反应情况来决定是否可以继续事务的PreCommit操作。根据响应情况，有以下两种可能。A.假如Coordinator从所有的Cohort获得的反馈都是Yes响应，那么就会进行事务的预执行：发送预提交请求。Coordinator向Cohort发送PreCommit请求，并进入Prepared阶段。事务预提交。Cohort接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。响应反馈。如果Cohort成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 B.假如有任何一个Cohort向Coordinator发送了No响应，或者等待超时之后，Coordinator都没有接到Cohort的响应，那么就中断事务：发送中断请求。Coordinator向所有Cohort发送abort请求。中断事务。Cohort收到来自Coordinator的abort请求之后（或超时之后，仍未收到Cohort的请求），执行事务的中断。 3.DoCommit阶段 该阶段进行真正的事务提交，也可以分为以下两种情况: 执行提交 A.发送提交请求。Coordinator接收到Cohort发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有Cohort发送doCommit请求。B.事务提交。Cohort接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。C.响应反馈。事务提交完之后，向Coordinator发送ACK响应。D.完成事务。Coordinator接收到所有Cohort的ACK响应之后，完成事务。 中断事务 Coordinator没有接收到Cohort发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 三阶段是为了解决2阶段提交的阻塞问题。 三阶段提交协议的缺点如果进入PreCommit后，Coordinator发出的是abort请求，假设只有一个Cohort收到并进行了abort操作，而其他对于系统状态未知的Cohort会根据3PC选择继续Commit，此时系统状态发生不一致性。 tcc(try-confirm-cancel) 柔性事务tcc 的具体实现华为的servicecomb-pack通过mq处理分布式事务阿里的setaByteTcchmilytcc-transaction","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"},{"name":"事务","slug":"事务","permalink":"http://yoursite.com/tags/事务/"}]},{"title":"nginx的基本操作配置","slug":"nginx_base","date":"2019-09-07T08:00:00.000Z","updated":"2021-08-23T08:29:40.708Z","comments":true,"path":"2019/09/07/nginx_base/","link":"","permalink":"http://yoursite.com/2019/09/07/nginx_base/","excerpt":"","text":"反向代理配置1反向代理代理的是服务端 代码示例： 1234567891011121314151617181920212223server &#123; listen 80; #对外暴露 listen [::]:80; server_name prewww.okkong.com;#限制访问的域名，可以有多个名称，中间用空格隔开，只有这些域名访问的才会代理到这个server配置下 root /okkong/kong/web/www/; #静态资源访问的根路径 index index.html index.htm index.php; # 设置网站的默认首页 include /etc/nginx/default.d/*.conf; #依赖的额外配置 location / &#123; try_files $uri $uri/ /index.html; &#125; ## 反向代理设置 location /api/ &#123; proxy_pass http://127.0.0.1:8880; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; ##请求访问的外网ip proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; &#125; error_page 404 500 502 503 504 /upgrade.html; location = /upgrade.html &#123; root /usr/share/nginx/html/okni-status-html-master/upgrade; &#125; &#125; 请求gzip压缩1234567891011server &#123; listen 80; server_name test.com www.test.com; root /webroot/www; location ~ .*\\.(jpg|gif|png|bmp)$ &#123; gzip on; #开启gzip压缩 gzip_http_version 1.1; gzip_comp_level 3; gzip_types text/plain application/json application/x-javascript application/css application/xml application/xml+rss text/javascript application/x-httpd-php image/jpeg image/gif image/png image/x-ms-bmp; &#125; &#125; 正向代理配置1正向代理代理的是客户端，类似上网用的vpn。 tcp 代理配置默认不开启tcp代理，需要编译时候开启 123456cd /usr/local/srcwget http://nginx.org/download/nginx-1.12.1.tar.gztar zxf nginx-1.12.1.tar.gzcd nginx-1.12.1./configure --prefix=/usr/local/nginx --with-stream --without-httpmake &amp;&amp; make install 需要添加的配置： 123456789stream &#123; server &#123; listen 3000; proxy_pass 127.0.0.1:3306; # 也支持socket # proxy_pass unix:/var/lib/mysql/mysql.socket; &#125;&#125; 测试的例子，可以考虑测试mysql的链接，这个后续经过自己测试再添加。 udp 代理配置12345678910111213events &#123; use epoll; worker_connections 1024;&#125;stream &#123; server &#123; listen 3000 udp; proxy_pass 127.0.0.1:3001; &#125;&#125; 参考资料12https://www.jianshu.com/p/244386221cc5https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"linux基本操作","slug":"linux_base_tool","date":"2019-09-04T16:00:00.000Z","updated":"2021-08-23T08:29:40.707Z","comments":true,"path":"2019/09/05/linux_base_tool/","link":"","permalink":"http://yoursite.com/2019/09/05/linux_base_tool/","excerpt":"","text":"1.CPU占用最多的前10个进程：1ps auxw|head -1;ps auxw|sort -rn -k3|head -10 2.内存消耗最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k4|head -10 3.虚拟内存使用最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k5|head -10 查看 内存信息查看内存的统计信息 1free -h 查看某个进程内存的具体使用信息 1pmap -X pid ###查看文件句柄数 1cat /proc/sys/fs/file-nr 查看tcp连接数 1netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; 查看oom 信息 1sudo dmesg | grep -i kill | less 123 /proc/$PID/oom_adj/proc/$PID/oom_score/proc/$PID/oom_score_adj 1ps -eo pid,comm,pmem --sort -rss | awk &apos;&#123;&quot;cat /proc/&quot;$1&quot;/oom_score&quot; | getline oom; print $0&quot;\\t&quot;oom&#125;&apos; 查看硬盘问题 1234df -lhdu -sh /*lsof |grep deletedu|sort -nr|more https://qsli.github.io/2017/12/02/google-perf-tools/","raw":null,"content":null,"categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"G1垃圾收集器配置","slug":"G1垃圾收集器配置","date":"2019-09-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.703Z","comments":true,"path":"2019/09/02/G1垃圾收集器配置/","link":"","permalink":"http://yoursite.com/2019/09/02/G1垃圾收集器配置/","excerpt":"","text":"常用的配置整理 可选项及默认值 描述 -XX:+UseG1GC G1收集器启动 -XX:MaxGCPauseMillis=n 垃圾收集的预期时间，尽量让实际收集时间和预期时间接近 -XX:InitiatingHeapOccupancyPercent=n 设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。默认值 45.tip:避免使用 -Xmn 选项或 -XX:NewRatio 等其他相关选项显式设置年轻代大小。固定年轻代的大小会覆盖暂停时间目标。 -XX:NewRatio=n new/old 年代的大小比例. 默认值 2.G1 一般不设置这个值，而是通过设置 -XX:ConcGCThreads=n 设置并行标记的线程数。将 n 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右 -XX:ParallelGCThreads=n 垃圾收集的线程数，一般逻辑处理器的数量 -XX:SurvivorRatio=n eden/survivor 空间的大小比例. 默认值 8. -XX:G1HeapRegionSize=n 使用G1，Java堆被划分为大小均匀的区域。这个参数配置各个子区域的大小。此参数的默认值根据堆大小的人工进行确定。最小值为 1Mb 且最大值为 32Mb，一般是2048个region，2G的内存空间设置为1M。 -XX:SurvivorRatio=n eden/survivor 空间的大小比例. 默认值 8. -XX:+DisableExplicitGC 禁止在程序中System.gc -XX:+UseTLAB 优先尝试在TALB空间分配内存。如果是新生代分配，会同步锁定，tlab无所分配，所以效率相对稳定。 日记配置整理-verbose:gc-XX:+HeapDumpOnOutOfMemoryError-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintGCDateStamps-XX:+PrintAdaptiveSizePolicy-Xloggc:/appl/gclogs/gc.log 试验性虚拟机标志 可选项及默认值 描述 XX:+UnlockExperimentalVMOptions 解锁试验性虚拟起标志 -XX:G1MixedGCLiveThresholdPercent -XX:G1HeapWastePercent -XX:G1MixedGCCountTarge -XX:G1OldCSetRegionThresholdPercent 设置老年代可回收的阀值 关于堆内存满的问题可以优化的点 1: 目标时间，设置短一点，减少吞吐量，但增加稳定行2：增加并行标记时间-XX:ConcGCThreads=n，但一般为可能太大。 1234567891011121314151617181920触发Full GC在某些情况下，G1触发了Full GC，这时G1会退化使用Serial收集器来完成垃圾的清理工作，它仅仅使用单线程来完成GC工作，GC暂停时间将达到秒级别的。整个应用处于假死状态，不能处理任何请求，我们的程序当然不希望看到这些。那么发生Full GC的情况有哪些呢？并发模式失败G1启动标记周期，但在Mix GC之前，老年代就被填满，这时候G1会放弃标记周期。这种情形下，需要增加堆大小，或者调整周期（例如增加线程数-XX:ConcGCThreads等）。晋升失败或者疏散失败G1在进行GC的时候没有足够的内存供存活对象或晋升对象使用，由此触发了Full GC。可以在日志中看到(to-space exhausted)或者（to-space overflow）。解决这种问题的方式是：a,增加 -XX:G1ReservePercent 选项的值（并相应增加总的堆大小），为“目标空间”增加预留内存量。b,通过减少 -XX:InitiatingHeapOccupancyPercent 提前启动标记周期。c,也可以通过增加 -XX:ConcGCThreads 选项的值来增加并行标记线程的数目。巨型对象分配失败当巨型对象找不到合适的空间进行分配时，就会启动Full GC，来释放空间。这种情况下，应该避免分配大量的巨型对象，增加内存或者增大-XX:G1HeapRegionSize，使巨型对象不再是巨型对象。由于篇幅有限，G1还有很多调优实践，在此就不一一列出了，大家在平常的实践中可以慢慢探索。最后，期待java 9能正式发布，默认使用G1为垃圾收集器的java性能会不会又提高呢？ 参考资料：1https://blog.csdn.net/u013380694/article/details/83341913","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"ignite整理","slug":"ignite整理","date":"2019-09-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.706Z","comments":true,"path":"2019/09/02/ignite整理/","link":"","permalink":"http://yoursite.com/2019/09/02/ignite整理/","excerpt":"","text":"简介ignite 是一个关系型的，可扩展的内存数据库，主要用于高速更新的数据的实时查询和关联查询，支持sql查询和流数据的插入。目前主要用于矿机实时数据的收集。优点 ：支持sql查询缺点：查询数据不稳定，表和cache的绑定这块目前做的不够好，增加字段需要修改配置，重启启动和加载数据。 创建表和cache的关联，只能在public schema 操作12345678CREATE TABLE IF NOT EXISTS person ( id int, city_id int, name varchar, age int, company varchar, PRIMARY KEY (id, city_id)) WITH &quot;ATOMICITY=ATOMIC,WRITE_SYNCHRONIZATION_MODE=PRIMARY_SYNC,cache_name=PersonCache,template=partitioned,backups=1,affinity_key=city_id, key_type=org.apache.ignite.cache.affinity.AffinityKey, value_type=com.okni.okkong.data.common.entity.Person&quot;; 上面的操作会创建一个 SQL_PUBLIC_PERSON 的cache，数据并置的维度是city_id。 123456优点: 动态生成，可扩展性强。 支持动态重启，不会影响到表结构。缺点: 只能在 sechma PUBLIC下动态生成。 做为主键的id,city_id不展现在表里面。 参考资料1https://apacheignite-sql.readme.io/docs/create-table 配置文件生成，参考ignite 官网1https://console.gridgain.com/","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"cache","slug":"cache","permalink":"http://yoursite.com/tags/cache/"},{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/tags/ignite/"},{"name":"内存关系型数据库","slug":"内存关系型数据库","permalink":"http://yoursite.com/tags/内存关系型数据库/"}]},{"title":"jvm内存问题定位","slug":"jvm 内存问题定位","date":"2019-09-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.707Z","comments":true,"path":"2019/09/02/jvm 内存问题定位/","link":"","permalink":"http://yoursite.com/2019/09/02/jvm 内存问题定位/","excerpt":"","text":"linux 进程 内存查看ps -p $pid -o rss,vsz查看应用逻辑内存，和实际物理内存使用。 pmap -x $pid | sort -n -k3top -csar123怀疑CPU存在瓶颈，可用 sar -u 和 sar -q 等来查看怀疑内存存在瓶颈，可用sar -B、sar -r 和 sar -W 等来查看怀疑I/O存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看 参考资料1https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/sar.html gdbgdb –batch –pid 11 -ex “dump memory a.dump 0x7fd488000000 0x7fd488000000+56124000” 123strings a.dump | lesshexdump -C a.dump | lessview a.dump 查看应用内存块。 strace堆内内存查看1 预先防范在启动项目的时候添加 12-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/temp/dumps 这种情况下，一旦内存溢出，会打印一个 *.hprof的文件 2 直接打印 .hprof ，线上慎用。1234jmap -heap 7732打印堆栈，有个问题，堆栈太大，怎么取分析jmap -histo:live -dump:live,format=b,file=accessservice.hprof 20048 3 hprof文件分析mat 内存分析： 1: 找到使用内存最多的元素 2: 可达性分析 3: 谁在引用。 相关资料https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/clopts001.html https://www.cnblogs.com/cellei/p/12240241.html 堆外内存查看安装 google-perftoolshttps://github.com/gperftools/gperftools 12https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/index.htmlhttp://www.brendangregg.com/perf.html Java NMT 查看线程的内存使用cat /proc/{pid}/smaps &gt; smaps.txt 参考资料： 1234https://www.jianshu.com/p/309c9f61d495https://blog.csdn.net/lycyingO/article/details/80854669https://blog.csdn.net/f529352479/article/details/51908655/ https://yq.aliyun.com/articles/713959?spm=5176.12825654.ez4uczyfi.8.55f32c4apCxjXo 需要解决的疑问young gc 什么时候触发 ？ full gc 什么时候触发？ jvm 的内存计算堆内内存 + 堆外内存+线程使用内存。 相关资料内存的定义1234VSS- Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）RSS- Resident Set Size 实际使用物理内存（包含共享库占用的内存）PSS- Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存）USS- Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存） mmap 文件1https://baike.baidu.com/item/mmap/1322217 很详细的一篇定位文章https://mp.weixin.qq.com/s/CPp9z45gvIzM8EasTgopfQ","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"jvm cpu 过高问题定位","slug":"java进程cpu过高问题定位","date":"2019-09-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.706Z","comments":true,"path":"2019/09/02/java进程cpu过高问题定位/","link":"","permalink":"http://yoursite.com/2019/09/02/java进程cpu过高问题定位/","excerpt":"","text":"操作步骤1:查找占用cpu高的进程 1top 2: 查看线程的cpu消耗 1top -Hp pid(进程号) 3:转换10进制为16进制 1234 printf &quot;%x\\n&quot; 线程ID``` 4: 查找执行的对应代码 jstack 进程ID |grep -a10 线程16进制ID```","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"高速缓存","slug":"多线程数据读取 -cpu 信","date":"2019-09-01T16:00:00.000Z","updated":"2021-08-23T08:29:40.711Z","comments":true,"path":"2019/09/02/多线程数据读取 -cpu 信/","link":"","permalink":"http://yoursite.com/2019/09/02/多线程数据读取 -cpu 信/","excerpt":"","text":"cpu –&gt; L1缓存-单线程共享，L2缓存 -&gt; 单cpu共享，L3缓存 – &gt;主内存查看 mac电脑的 L2cache 和L3 cache查看cpu的物理核：sysctl hw.physicalcpu 查看cpu的逻辑核：sysctl hw.logicalcpu查看内存的具体信息system_profiler SPHardwareDataTypeLinxu 查看 cpu 信息 ： lscpu L1d 缓存 : L1缓存 数据存储区L1i 缓存：L1缓存数据计算区 java 的 volatile 基于MESI 协议，当高速缓存的数据变更的时候，会通知其他cpu的高速缓存该变量已经无效 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"cache","slug":"cache","permalink":"http://yoursite.com/tags/cache/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"}]},{"title":"比特币的历史","slug":"比特币","date":"2017-09-16T04:04:46.000Z","updated":"2021-08-23T08:29:40.711Z","comments":true,"path":"2017/09/16/比特币/","link":"","permalink":"http://yoursite.com/2017/09/16/比特币/","excerpt":"","text":"2009年1月3号：中本聪在位于芬兰赫尔辛基的一个小型服务器上挖出了第一批比特币，创世比特币。2010年5月21号：第一次比特币交易：佛罗里达程序员Laszlo Hanyecz用1万BTC购买了价值25美元的披萨优惠券。这项交易诞生了比特币第一个公允汇率。用10000万比特币买两个比特币优惠券的故事。2010年7月11日，比特币新版客户端消息被著名新闻网站Slashdot提及，为比特币带来大量新用户，嗯，说明slashdot是一个比较OK的网站。2010年7月16日，经过为期5天的10倍暴涨，BTC价格从0.008美元升值0.08美元，第一次价格的剧烈波动，显示新生事物的崛起比特币之一年震荡 2012年3月1日，服务器超级管理密码泄漏，价值228845美元的46703比特币失窃，黑客是比特币世界挥之不去的恶梦 2012年7月22日，用户在bicoin官方论坛上总计发表了100万个帖子，此时比特币价格为8.77美元 2012年9月15日，伦敦比特币会议召开，此时比特币价格为11.8美元 2012年9月27日，比特币基金创立，此时比特币价格为12.46美元 2012年11月25日，欧洲第一次比特币会议在捷克布拉格召开，此时比特币价格为12.6美元 2012年11月28日，区块供应量首次减半调整，从之前每10分钟50个递减至25个，同时比特币发行量占道发行总量2100万的一半，此时比特币价格为12.4美元 2012年12月6日，首家在欧盟法律框架下进行运作的比特币交易所–法国比特币中央交易所诞生，这是世界首家官方认可的比特币交易所，此时比特币价格为13.69美元 2013年2月，日均PV4000万的社交新闻网站Reddit宣布付费服务将接受比特币付款 2013年2月8日，coinbase宣称每月交易量达100W每月的比特币，此时比特币价格为22.7美元 2013年2月19日，比特币客户端V8.0发布，此时比特币价格为28.66美元 2013年2月28日，BTC价格在601天之后，超越2011年6月8日的历史最高点31.91美元 比特币之疯狂暴涨 2013年3月16日，人口仅110万的欧盟成员国塞浦路斯政府冻结民众银行转账交易，对银行存款账户征税，18日关闭银行和股市，此时比特币价格为47.45美元 2013年3月18日，美国财政部金融犯罪执法系统FinCEN发布了虚拟货币个人管理条例，首次阐明了虚拟货币，此时比特币价格为47.8美元 2013年3月28日，比特币总市值超过10亿美元，均价为92美元 2013年4月1日，比特币价格在所有交易市场超过100美元 2013年4月10日，BTC创下历史最高价，266美元 比特币之理性回归 2013年4月16日，Mt.Mox平台成交创天量，达61W，换手率5.8%。此时比特币价格为71.76美元 2013年4月20日，四川芦山地震当天，李笑来在bitcoin官网发起对灾区的比特币捐赠，中国壹基金此后宣称共计收到捐赠比特币233个，市值22万人民币，此时比特币价格为121美元 2013年5月3日，中国央视《经济半小时》比较客观的向中国观众第一次介绍比特币这个新生事物，此时比特币价格为92美元 2013年5月9日，比特币公司Coinbase获得了投资基金Union Square的500万美元A轮投资，此时比特币价格为112.09美元 2013年5月14日，美国国土安全部获得法院许可，冻结了全球最大的比特币交易所Mt.Gox的两个账户，此时比特币价格为119.4美元 2013年5月17日，2013年圣何塞比特币大会召开，1300人参与，此时比特币价格为119.1美元 2013年5月28日，美国国土安全部以涉嫌洗钱和无证经营资金汇划业务取缔了位于哥斯达黎加的汇兑公司Liberty Reserve的虚拟货币服务，美国检察官称这将成为历史上最大的国际洗钱诉讼案，吸钱规模达到60亿美元，包括中国在内的大量用户血本无归，此时比特币价格为128美元 2013年6月，网传美国将退出QE3，通缩的比特币，量化宽松的货币政策，两者是针尖对麦芒的关系 2013年6月27日，德国会议作出决定：持有比特币一年以上将予以免税，被业内认为此举变相认可了比特币的法律地位，此时比特币价格为102.24美元 2013年6月28日，MTGOX获得美国财政部金融犯罪执法网络处颁发的货币服务事务许可，交易规范化可能意味着比特币开始走向正轨，政府风险降低，其融入显示经济的步伐将会加快，同时会对其它虚拟货币起到示范作用，此时比特币价格为97.99美元 2013年7月7日，以中国为代表的矿机产业链日益成熟，比特币股票分红令人垂涎，随着越来越多的人士介入挖矿行业，挖矿难度与日俱增…","raw":null,"content":null,"categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/区块链/"}],"tags":[{"name":"btcoin","slug":"btcoin","permalink":"http://yoursite.com/tags/btcoin/"}]},{"title":"dubbo 学习","slug":"dubbo-学习","date":"2017-08-23T14:06:00.000Z","updated":"2021-08-23T08:29:40.705Z","comments":true,"path":"2017/08/23/dubbo-学习/","link":"","permalink":"http://yoursite.com/2017/08/23/dubbo-学习/","excerpt":"","text":"问题：1：RPC的实现是如何实现的?核心类：ReferenceConfig.createProxy()创建代理类,获取proxy代理类的顺序: 12345671. 如果没有url指定： 1:查找本地是否有接口2. 是否是url直连：3. 是否是注册中心连接： 配置文件加载： 1：配置文件获取。 2：环境变量（&quot;dubbo.registry.address&quot;）获取 第一步是生成代理类。第二部当方法调用的时候，通过代理类发送信息给实际的执行类，然后等待返回结果封装到自己的返回结果里面。rpc 的实现机制最终还是使用了jdk的动态代理的概念。 2：dubbo的数据传输的方式有几种？默认实现的方式：dubbohttphessianinjvmredisrmimemcachedthrift 3：dubbo事务的处理机制?4：dubbo客户端配置文件的加载，是如何从spring boots的资源文件加载的?5. dubbo的分布式服务端处理?6.filter的应用场景和实例?7 负载均衡是如何实现的?LoadBalance接口，根据策略在来做不同的选举。检查类的初始化 8 dubbo的分版本处理核心类：AnnotationBean.refer String key = reference.group() + &quot;/&quot; + interfaceName + &quot;:&quot; + reference.version(); ReferenceBean&lt;?&gt; referenceConfig = referenceConfigs.get(key); if (referenceConfig == null) { referenceConfig = new ReferenceBean&lt;Object&gt;(reference); if (void.class.equals(reference.interfaceClass()) &amp;&amp; &quot;&quot;.equals(reference.interfaceName()) &amp;&amp; referenceClass.isInterface()) { referenceConfig.setInterface(referenceClass); } ... 9 dubbo对jsr303的处理spring mvc对validate的处理需要显示的声明validate而dubbo不需要，根本原因是dubbo的传输协议会带过来validate的信息核心的实现类ValidationFilter 优雅关机、灰度发布、熔断策略，链路追踪，分布式事务扩展的思考：1. jDK的动态代理是如何实现的?参考的文章http://blog.csdn.net/mhmyqn/article/details/48474815上面的文章讲了下代理类生成的具体逻辑，但代理类和远程实现类的关联是如何实现的？代理类只是把远程的调用接口通过自己返回给了调用方","raw":null,"content":null,"categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"http://yoursite.com/tags/rpc/"}]},{"title":"hexo的通用命令","slug":"hexo","date":"2017-08-23T13:49:04.000Z","updated":"2021-08-23T08:29:40.706Z","comments":true,"path":"2017/08/23/hexo/","link":"","permalink":"http://yoursite.com/2017/08/23/hexo/","excerpt":"","text":"##常用命令 Create a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo s More info: Server Generate static files1$ hexo g More info: Generating Deploy to remote sites1$ hexo d","raw":null,"content":null,"categories":[{"name":"web前端","slug":"web前端","permalink":"http://yoursite.com/categories/web前端/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://yoursite.com/tags/nodejs/"},{"name":"博客","slug":"博客","permalink":"http://yoursite.com/tags/博客/"}]}]}